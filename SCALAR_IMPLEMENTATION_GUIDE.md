# Scalar æœ¬åœ°è‡ªæ‰˜ç®¡ - è¯¦ç»†å®æ–½æŒ‡å—

## ğŸ“‹ å®æ–½æ¦‚è¿°

**æ–¹æ¡ˆ**: Scalar æœ¬åœ°è‡ªæ‰˜ç®¡ï¼ˆæ–¹æ¡ˆ Aï¼‰
**æ—¶é—´**: 2 å‘¨ï¼ˆ10 ä¸ªå·¥ä½œæ—¥ï¼‰
**å›¢é˜Ÿ**: 1-2 äºº
**æˆæœ¬**: $0

**ç›®æ ‡æ¶æ„**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç”¨æˆ·æµè§ˆå™¨                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€ http://localhost:8000/docs (åŸ Swagger UI)
         â”œâ”€â”€â”€ http://localhost:7998 (æ–° Scalar UI) â­
         â””â”€â”€â”€ http://localhost:8000/api/v1/* (API ç›´è¿)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Docker Compose æœåŠ¡                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Scalar UI (7998) â”€â”€â–º FastAPI (8000)            â”‚
â”‚                       â””â”€ OpenAPI Spec           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“… 10 å¤©è¯¦ç»†è®¡åˆ’

### Day 1-2: OpenAPI è§„èŒƒå¢å¼º

#### ä»»åŠ¡æ¸…å•
- [x] å®¡è®¡å½“å‰ OpenAPI è§„èŒƒ
- [ ] å¢å¼º FastAPI å…ƒæ•°æ®
- [ ] ä¿®å¤ `/stream` ç«¯ç‚¹å®šä¹‰
- [ ] æ·»åŠ ä¸°å¯Œçš„ examples
- [ ] éªŒè¯è§„èŒƒåˆæ³•æ€§

---

### Day 3-4: Scalar æœåŠ¡é›†æˆ

#### ä»»åŠ¡æ¸…å•
- [ ] æ·»åŠ  Scalar åˆ° docker-compose
- [ ] é…ç½®ç¯å¢ƒå˜é‡
- [ ] æµ‹è¯•æœ¬åœ°è®¿é—®
- [ ] ä¼˜åŒ– UI ä¸»é¢˜

---

### Day 5-6: æ–‡æ¡£è´¨é‡æå‡

#### ä»»åŠ¡æ¸…å•
- [ ] æ·»åŠ ä»£ç ç¤ºä¾‹
- [ ] å®Œå–„é”™è¯¯å“åº”
- [ ] æ·»åŠ è®¤è¯è¯´æ˜
- [ ] åˆ›å»ºå¿«é€Ÿå¼€å§‹æŒ‡å—

---

### Day 7-8: æµ‹è¯•å’Œä¼˜åŒ–

#### ä»»åŠ¡æ¸…å•
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] SSE æµå¼æµ‹è¯•
- [ ] ä¿®å¤å‘ç°çš„é—®é¢˜

---

### Day 9-10: éƒ¨ç½²å’Œæ–‡æ¡£

#### ä»»åŠ¡æ¸…å•
- [ ] æ›´æ–° README
- [ ] ç¼–å†™ç”¨æˆ·æŒ‡å—
- [ ] å›¢é˜ŸåŸ¹è®­
- [ ] ä¸Šçº¿éªŒæ”¶

---

## ğŸ”§ Day 1-2: OpenAPI è§„èŒƒå¢å¼º

### æ­¥éª¤ 1.1: å¢å¼º FastAPI åº”ç”¨å…ƒæ•°æ®

**æ–‡ä»¶**: `src/main.py`

**å½“å‰ä»£ç **:
```python
app = FastAPI(
    title="arXiv Paper Curator API",
    description="Personal arXiv CS.AI paper curator with RAG capabilities",
    version=os.getenv("APP_VERSION", "0.1.0"),
    lifespan=lifespan,
)
```

**å¢å¼ºåçš„ä»£ç **:
```python
# src/main.py
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi

# ... existing imports ...

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ... existing lifespan code ...
    yield
    # ... existing cleanup code ...


# åˆ›å»º FastAPI åº”ç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰
app = FastAPI(
    title="arXiv Paper Curator API",
    description="""
# ğŸ“ Academic Research Assistant with RAG

A production-grade Retrieval-Augmented Generation system for academic papers from arXiv.

## ğŸŒŸ Key Features

- **Hybrid Search**: BM25 keyword search + Vector similarity (Jina 1024-dim)
- **Agentic RAG**: Intelligent retrieval with LangGraph decision-making
- **Real-time Monitoring**: Langfuse tracing for every request
- **High Performance**: Redis caching (6-hour TTL)
- **Streaming Support**: Server-Sent Events for real-time responses
- **Mobile Access**: Telegram bot integration

## ğŸš€ Quick Start

1. **Health Check**: `GET /api/v1/health` - Verify all services are running
2. **Search Papers**: `POST /api/v1/hybrid-search` - Find relevant papers
3. **Ask Questions**: `POST /api/v1/ask-agentic` - Get intelligent answers

## ğŸ“Š Architecture

```
User Query â†’ Guardrail â†’ Hybrid Search â†’ Document Grading â†’ Answer Generation
                â†“                              â†“
            Out of Scope?              Not Relevant? â†’ Query Rewriting
```

## ğŸ”— External Resources

- **Blog Series**: https://jamwithai.substack.com/p/the-mother-of-ai-project
- **GitHub**: https://github.com/jamwithai/arxiv-paper-curator
- **Langfuse Dashboard**: http://localhost:3000
- **Gradio UI**: http://localhost:7861

## ğŸ“ Support

For issues and feature requests, visit our [GitHub Issues](https://github.com/jamwithai/arxiv-paper-curator/issues).
    """,
    version=os.getenv("APP_VERSION", "0.1.0"),
    lifespan=lifespan,

    # è”ç³»ä¿¡æ¯
    contact={
        "name": "arXiv Paper Curator Team",
        "url": "https://github.com/jamwithai/arxiv-paper-curator",
        "email": "support@jamwithai.com"
    },

    # è®¸å¯è¯
    license_info={
        "name": "MIT License",
        "url": "https://github.com/jamwithai/arxiv-paper-curator/blob/main/LICENSE"
    },

    # æœåŠ¡å™¨é…ç½®
    servers=[
        {
            "url": "http://localhost:8000",
            "description": "ğŸ› ï¸ Development Server (Local)"
        },
        {
            "url": "http://api.arxiv-curator.local",
            "description": "ğŸ³ Docker Internal Network"
        }
    ],

    # Tags åˆ†ç±»ï¼ˆç”¨äº Scalar åˆ†ç»„ï¼‰
    openapi_tags=[
        {
            "name": "Health",
            "description": "ğŸ¥ **System Health & Monitoring**\n\nMonitor the health of all backend services including PostgreSQL, OpenSearch, and Ollama.",
            "externalDocs": {
                "description": "Health Check Best Practices",
                "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/health-endpoint-monitoring"
            }
        },
        {
            "name": "hybrid-search",
            "description": "ğŸ” **Hybrid Document Search**\n\nSearch academic papers using BM25 (keyword) and vector similarity. Uses Reciprocal Rank Fusion (RRF) for optimal results.",
            "externalDocs": {
                "description": "Learn about Hybrid Search",
                "url": "https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"
            }
        },
        {
            "name": "ask",
            "description": "ğŸ’¬ **Basic RAG Q&A**\n\nBasic Retrieval-Augmented Generation with caching. Fast responses for repeated queries.",
        },
        {
            "name": "stream",
            "description": "âš¡ **Streaming Responses**\n\nReal-time streaming with Server-Sent Events. Ideal for chat interfaces.",
        },
        {
            "name": "agentic-rag",
            "description": "ğŸ¤– **Agentic RAG (LangGraph)**\n\n**Intelligent RAG with Decision-Making**\n\n- Query validation (Guardrail)\n- Adaptive retrieval (Document grading)\n- Automatic query rewriting\n- Full reasoning transparency\n\n**Workflow**: Guardrail â†’ Retrieve â†’ Grade â†’ Rewrite/Generate",
            "externalDocs": {
                "description": "Agentic RAG Tutorial",
                "url": "https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"
            }
        }
    ],

    # Swagger UI é…ç½®ï¼ˆä¿ç•™ç”¨äºå¯¹æ¯”ï¼‰
    swagger_ui_parameters={
        "defaultModelsExpandDepth": -1,  # éšè— schemas
        "docExpansion": "list",
        "filter": True,
        "syntaxHighlight.theme": "monokai"
    },

    # ReDoc é…ç½®
    redoc_url="/redoc",

    # å“åº”ç¤ºä¾‹é…ç½®
    generate_unique_id_function=lambda route: f"{route.tags[0]}_{route.name}" if route.tags else route.name
)


# è‡ªå®šä¹‰ OpenAPI Schema (æ·»åŠ  Scalar ä¼˜åŒ–)
def custom_openapi():
    """Generate enhanced OpenAPI schema for Scalar"""
    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
        tags=app.openapi_tags,
        servers=app.servers,
        contact=app.contact,
        license_info=app.license_info,
    )

    # æ·»åŠ  x-logo (Scalar è‡ªå®šä¹‰æ‰©å±•)
    openapi_schema["info"]["x-logo"] = {
        "url": "https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/logo.png",
        "altText": "arXiv Paper Curator Logo"
    }

    # æ·»åŠ å…¨å±€å®‰å…¨æ–¹æ¡ˆå®šä¹‰ï¼ˆæœªæ¥ä½¿ç”¨ï¼‰
    openapi_schema["components"]["securitySchemes"] = {
        "ApiKeyAuth": {
            "type": "apiKey",
            "in": "header",
            "name": "X-API-Key",
            "description": "API key for authentication (future implementation)"
        },
        "BearerAuth": {
            "type": "http",
            "scheme": "bearer",
            "bearerFormat": "JWT",
            "description": "JWT bearer token (future implementation)"
        }
    }

    # Scalar ç‰¹å®šæ‰©å±•
    openapi_schema["x-tagGroups"] = [
        {
            "name": "Core Services",
            "tags": ["Health", "hybrid-search"]
        },
        {
            "name": "RAG Endpoints",
            "tags": ["ask", "stream", "agentic-rag"]
        }
    ]

    app.openapi_schema = openapi_schema
    return app.openapi_schema


# åº”ç”¨è‡ªå®šä¹‰ OpenAPI
app.openapi = custom_openapi

# Include routers (existing code)
app.include_router(ping.router, prefix="/api/v1")
app.include_router(hybrid_search.router, prefix="/api/v1")
app.include_router(ask_router, prefix="/api/v1")
app.include_router(stream_router, prefix="/api/v1")
app.include_router(agentic_ask.router)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, port=8000, host="0.0.0.0")
```

---

### æ­¥éª¤ 1.2: ä¿®å¤ `/stream` ç«¯ç‚¹çš„ OpenAPI å®šä¹‰

**é—®é¢˜**: SSE å“åº”æ²¡æœ‰æ˜ç¡®çš„ schema

**æ–‡ä»¶**: `src/routers/ask.py`

**æ·»åŠ  SSE Schema å®šä¹‰**:
```python
# src/routers/ask.py
from typing import Optional, List
from pydantic import BaseModel, Field

# ... existing imports ...

# æ–°å¢: SSE äº‹ä»¶ Schema
class SSEMetadataEvent(BaseModel):
    """First SSE event with metadata"""
    sources: List[str] = Field(..., description="List of source PDF URLs")
    chunks_used: int = Field(..., description="Number of chunks retrieved")
    search_mode: str = Field(..., description="Search mode: bm25 or hybrid")

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "sources": ["https://arxiv.org/pdf/1706.03762.pdf"],
                "chunks_used": 3,
                "search_mode": "hybrid"
            }
        }
    )


class SSEChunkEvent(BaseModel):
    """Streaming text chunk event"""
    chunk: str = Field(..., description="Text fragment from LLM")

    model_config = ConfigDict(
        json_schema_extra={
            "example": {"chunk": "Based on "}
        }
    )


class SSEDoneEvent(BaseModel):
    """Final completion event"""
    answer: str = Field(..., description="Complete generated answer")
    done: bool = Field(True, description="Stream completion flag")

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "answer": "Transformers are neural network architectures...",
                "done": True
            }
        }
    )


class SSEErrorEvent(BaseModel):
    """Error event"""
    error: str = Field(..., description="Error message")

    model_config = ConfigDict(
        json_schema_extra={
            "example": {"error": "Search service unavailable"}
        }
    )


# ä¿®æ”¹ /stream ç«¯ç‚¹
@stream_router.post(
    "/stream",
    responses={
        200: {
            "description": "Server-Sent Events stream with JSON payloads",
            "content": {
                "text/event-stream": {
                    "schema": {
                        "type": "string",
                        "format": "binary",
                        "description": "SSE stream with newline-delimited JSON events"
                    },
                    "examples": {
                        "complete_flow": {
                            "summary": "Complete SSE Flow",
                            "value": """data: {"sources": ["https://arxiv.org/pdf/1706.03762.pdf"], "chunks_used": 3, "search_mode": "hybrid"}

data: {"chunk": "Based on "}

data: {"chunk": "the research "}

data: {"chunk": "papers, "}

data: {"answer": "Based on the research papers, transformers...", "done": true}
"""
                        }
                    }
                }
            }
        },
        500: {
            "description": "Server error during streaming",
            "content": {
                "text/event-stream": {
                    "example": 'data: {"error": "Internal server error"}\n\n'
                }
            }
        }
    },
    summary="Stream RAG answer in real-time",
    description="""
## Real-time Streaming RAG

Get RAG answers with **Server-Sent Events (SSE)** for a better user experience.

### Event Sequence

1. **Metadata Event** (first):
   ```json
   {"sources": [...], "chunks_used": 3, "search_mode": "hybrid"}
   ```

2. **Chunk Events** (multiple):
   ```json
   {"chunk": "text fragment "}
   ```

3. **Done Event** (last):
   ```json
   {"answer": "complete answer text", "done": true}
   ```

4. **Error Event** (if failed):
   ```json
   {"error": "error message"}
   ```

### Usage Examples

#### JavaScript (Browser)
```javascript
const response = await fetch('/api/v1/stream', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        query: "What are transformers?",
        top_k: 3
    })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
    const {done, value} = await reader.read();
    if (done) break;

    const text = decoder.decode(value);
    const lines = text.split('\\n');

    for (const line of lines) {
        if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));

            if (data.chunk) {
                console.log(data.chunk);  // Display chunk
            }
            if (data.done) {
                console.log('Complete:', data.answer);
            }
        }
    }
}
```

#### Python (httpx)
```python
import httpx
import json

async with httpx.AsyncClient() as client:
    async with client.stream(
        "POST",
        "http://localhost:8000/api/v1/stream",
        json={"query": "What are transformers?", "top_k": 3}
    ) as response:
        async for line in response.aiter_lines():
            if line.startswith("data: "):
                data = json.loads(line[6:])
                if "chunk" in data:
                    print(data["chunk"], end="", flush=True)
                if data.get("done"):
                    print(f"\\n\\nComplete: {data['answer']}")
```

### Cache Behavior

- âœ… Exact cache hit: Streams cached response (simulated)
- âŒ Cache miss: Real-time LLM generation

### Performance

- First byte latency: < 500ms
- Chunk frequency: 10-50 chunks/second
- Total time: 2-8 seconds (depends on answer length)
    """,
    operation_id="stream_rag_answer",
    tags=["stream"]
)
async def ask_question_stream(
    request: AskRequest,
    opensearch_client: OpenSearchDep,
    embeddings_service: EmbeddingsDep,
    ollama_client: OllamaDep,
    langfuse_tracer: LangfuseDep,
    cache_client: CacheDep,
) -> StreamingResponse:
    # ... existing implementation ...
    pass
```

---

### æ­¥éª¤ 1.3: å¢å¼ºæ‰€æœ‰ Schema çš„ Examples

**æ–‡ä»¶**: `src/schemas/api/ask.py`

**å¢å¼ºåçš„ä»£ç **:
```python
# src/schemas/api/ask.py
from typing import List, Optional
from pydantic import BaseModel, Field, ConfigDict

class AskRequest(BaseModel):
    """Request model for RAG question answering."""

    query: str = Field(
        ...,
        description="User's question about academic research papers",
        min_length=1,
        max_length=1000,
        examples=[
            "What are the key differences between transformers and RNNs?",
            "Explain the attention mechanism in BERT",
            "What are the latest developments in quantum computing?",
            "How do vision transformers work?",
            "What is federated learning?"
        ]
    )

    top_k: int = Field(
        3,
        description="Number of top document chunks to retrieve for context",
        ge=1,
        le=10,
        examples=[3, 5, 10]
    )

    use_hybrid: bool = Field(
        True,
        description="Enable hybrid search (BM25 + vector similarity). Falls back to BM25 if embedding fails.",
        examples=[True, False]
    )

    model: str = Field(
        "llama3.2:1b",
        description="Ollama model name for answer generation. Available: llama3.2:1b, llama3.2:3b, qwen2.5:7b",
        examples=["llama3.2:1b", "llama3.2:3b", "qwen2.5:7b"]
    )

    categories: Optional[List[str]] = Field(
        None,
        description="Filter papers by arXiv categories. Leave empty for all categories.",
        examples=[
            ["cs.AI", "cs.LG"],
            ["cs.CV"],
            ["cs.CL", "cs.AI", "cs.LG"]
        ]
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {
                    "query": "What are transformers in machine learning?",
                    "top_k": 3,
                    "use_hybrid": True,
                    "model": "llama3.2:1b"
                },
                {
                    "query": "Explain self-attention mechanism in detail",
                    "top_k": 5,
                    "use_hybrid": True,
                    "model": "llama3.2:3b",
                    "categories": ["cs.AI", "cs.LG"]
                },
                {
                    "query": "Latest research on quantum machine learning",
                    "top_k": 10,
                    "use_hybrid": False,
                    "model": "qwen2.5:7b",
                    "categories": ["quant-ph", "cs.LG"]
                }
            ]
        }
    )


class AskResponse(BaseModel):
    """Response model for RAG question answering."""

    query: str = Field(
        ...,
        description="Original user question (echoed back)"
    )

    answer: str = Field(
        ...,
        description="Generated answer from LLM based on retrieved context"
    )

    sources: List[str] = Field(
        ...,
        description="List of source paper PDF URLs cited in the answer"
    )

    chunks_used: int = Field(
        ...,
        description="Number of document chunks used for context",
        ge=0
    )

    search_mode: str = Field(
        ...,
        description="Search mode used: 'bm25' (keyword only) or 'hybrid' (BM25 + vector)"
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {
                    "query": "What are transformers in machine learning?",
                    "answer": "Based on the research papers, transformers are neural network architectures that rely entirely on attention mechanisms, eliminating the need for recurrence and convolutions. The key innovation is the self-attention mechanism that allows the model to weigh the importance of different words in the input when processing each word.\n\nKey advantages:\n1. Parallelization during training\n2. Better handling of long-range dependencies\n3. State-of-the-art performance on NLP tasks\n\nSource: Attention is All You Need (Vaswani et al., 2017)",
                    "sources": [
                        "https://arxiv.org/pdf/1706.03762.pdf",
                        "https://arxiv.org/pdf/1810.04805.pdf"
                    ],
                    "chunks_used": 3,
                    "search_mode": "hybrid"
                },
                {
                    "query": "What is quantum computing?",
                    "answer": "I couldn't find any relevant information in the papers to answer your question. The available papers focus on CS and AI topics. Please try a question related to machine learning, NLP, or computer vision.",
                    "sources": [],
                    "chunks_used": 0,
                    "search_mode": "bm25"
                }
            ]
        }
    )


# ç±»ä¼¼åœ°å¢å¼ºå…¶ä»– schemas...
class AgenticAskResponse(AskResponse):
    """Response model for agentic RAG question answering."""

    reasoning_steps: List[str] = Field(
        ...,
        description="Step-by-step reasoning process of the agent",
        examples=[
            [
                "âœ“ Query validation: Academic research scope confirmed (score: 85/100)",
                "âœ“ Document retrieval: Retrieved 3 candidate chunks",
                "âœ“ Relevance grading: All 3 chunks marked as relevant",
                "âœ“ Answer generation: Generated response from context"
            ],
            [
                "âœ“ Query validation: Passed (score: 78/100)",
                "âœ“ Document retrieval (Attempt 1): Retrieved 3 chunks",
                "âœ— Relevance grading: 0/3 chunks relevant",
                "âŸ³ Query rewriting: Optimized query for better retrieval",
                "âœ“ Document retrieval (Attempt 2): Retrieved 3 chunks",
                "âœ“ Relevance grading: 2/3 chunks relevant",
                "âœ“ Answer generation: Generated response from 2 relevant chunks"
            ]
        ]
    )

    retrieval_attempts: int = Field(
        ...,
        description="Number of document retrieval attempts (1-2)",
        ge=1,
        le=2
    )

    trace_id: Optional[str] = Field(
        None,
        description="Langfuse trace ID for feedback submission and debugging"
    )

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [
                {
                    "query": "What are the key innovations in GPT-3?",
                    "answer": "Based on recent research, GPT-3 introduced several key innovations:\n\n1. **Scale**: 175 billion parameters, significantly larger than GPT-2\n2. **Few-shot learning**: Can perform tasks with minimal examples\n3. **In-context learning**: Adapts to tasks via prompts without fine-tuning\n\nThese innovations demonstrate that language models can achieve strong performance through scale and appropriate prompting strategies.\n\nSources: Language Models are Few-Shot Learners (Brown et al., 2020)",
                    "sources": ["https://arxiv.org/pdf/2005.14165.pdf"],
                    "chunks_used": 3,
                    "search_mode": "hybrid",
                    "reasoning_steps": [
                        "âœ“ Query validation: Academic research scope confirmed (score: 92/100)",
                        "âœ“ Document retrieval: Retrieved 3 candidate chunks about GPT-3",
                        "âœ“ Relevance grading: All 3 chunks highly relevant",
                        "âœ“ Answer generation: Synthesized response from context"
                    ],
                    "retrieval_attempts": 1,
                    "trace_id": "langfuse-trace-abc123-def456-ghi789"
                }
            ]
        }
    )
```

---

### æ­¥éª¤ 1.4: éªŒè¯ OpenAPI è§„èŒƒ

**åˆ›å»ºéªŒè¯è„šæœ¬**: `scripts/validate_openapi.sh`

```bash
#!/bin/bash
# scripts/validate_openapi.sh

set -e

echo "ğŸ” Validating OpenAPI Specification..."

# 1. Start API if not running
if ! curl -s http://localhost:8000/health > /dev/null 2>&1; then
    echo "âš ï¸  API not running, starting docker-compose..."
    docker compose up -d api
    echo "â³ Waiting for API to be ready..."
    sleep 10
fi

# 2. Download OpenAPI spec
echo "ğŸ“¥ Downloading OpenAPI spec..."
curl -s http://localhost:8000/openapi.json > openapi.json

# 3. Validate with Scalar CLI
echo "âœ… Validating with Scalar CLI..."
npx @scalar/cli validate openapi.json --strict

# 4. Check required fields
echo "ğŸ” Checking required fields..."

# Check all endpoints have operation_id
MISSING_OP_ID=$(jq '.paths | to_entries[] | select(.value | to_entries[] | select(.value.operationId == null)) | .key' openapi.json)
if [ -n "$MISSING_OP_ID" ]; then
    echo "âŒ Missing operation_id in endpoints: $MISSING_OP_ID"
    exit 1
fi

# Check all endpoints have examples
MISSING_EXAMPLES=$(jq '[.paths[][] | select(.requestBody.content."application/json".schema.examples == null and .requestBody.content."application/json".examples == null)] | length' openapi.json)
if [ "$MISSING_EXAMPLES" -gt 0 ]; then
    echo "âš ï¸  Warning: $MISSING_EXAMPLES endpoints missing examples"
fi

# Check all responses have descriptions
MISSING_DESC=$(jq '[.paths[][] | .responses[] | select(.description == null or .description == "")] | length' openapi.json)
if [ "$MISSING_DESC" -gt 0 ]; then
    echo "âš ï¸  Warning: $MISSING_DESC responses missing descriptions"
fi

echo "âœ… OpenAPI specification is valid!"

# 5. Generate summary
echo ""
echo "ğŸ“Š OpenAPI Summary:"
echo "  Total endpoints: $(jq '.paths | length' openapi.json)"
echo "  Total schemas: $(jq '.components.schemas | length' openapi.json)"
echo "  OpenAPI version: $(jq -r '.openapi' openapi.json)"

# 6. Save validated spec
cp openapi.json openapi.validated.json
echo "ğŸ’¾ Saved validated spec to openapi.validated.json"
```

**è¿è¡ŒéªŒè¯**:
```bash
chmod +x scripts/validate_openapi.sh
./scripts/validate_openapi.sh
```

---

## ğŸ³ Day 3-4: Scalar æœåŠ¡é›†æˆ

### æ­¥éª¤ 3.1: æ›´æ–° Docker Compose

**æ–‡ä»¶**: `compose.yml`

**åœ¨ç°æœ‰æœåŠ¡åæ·»åŠ  Scalar**:
```yaml
# compose.yml (æ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾)

  # ===================================================================
  # Scalar API Documentation UI
  # ===================================================================
  scalar:
    image: scalar/scalar-api-reference:latest
    container_name: arxiv-scalar-ui
    ports:
      - "7998:8080"
    environment:
      # OpenAPI Spec URL (ä» FastAPI åŠ¨æ€è·å–)
      - SPEC_URL=http://api:8000/openapi.json

      # Scalar UI é…ç½®
      - SCALAR_THEME=purple              # purple, blue, green, default
      - SCALAR_LAYOUT=modern              # modern, classic
      - SCALAR_SHOW_SIDEBAR=true
      - SCALAR_HIDE_MODELS=false          # æ˜¾ç¤º Schema æ¨¡å‹
      - SCALAR_HIDE_DOWNLOAD_BUTTON=false
      - SCALAR_HIDE_TEST_REQUEST_BUTTON=false

      # ä»£ç†é…ç½®ï¼ˆå…è®¸ç›´æ¥ä» Scalar UI è°ƒç”¨ APIï¼‰
      - SCALAR_PROXY_ENABLED=true
      - SCALAR_PROXY_URL=http://api:8000

      # è‡ªå®šä¹‰é…ç½®
      - SCALAR_DEFAULT_OPEN_ALL_TAGS=false
      - SCALAR_SHOW_OPERATIONS_ORDER=path  # path æˆ– method

    depends_on:
      api:
        condition: service_healthy
    networks:
      - rag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    labels:
      - "com.arxiv-curator.description=Scalar API Documentation UI"
      - "com.arxiv-curator.service=scalar"

networks:
  rag-network:
    # ... existing network config ...
```

**æ›´æ–° API å¥åº·æ£€æŸ¥**ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰:
```yaml
# compose.yml - ä¿®æ”¹ api æœåŠ¡
  api:
    # ... existing config ...
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

---

### æ­¥éª¤ 3.2: åˆ›å»º Scalar é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `.scalar/config.yml`

```yaml
# .scalar/config.yml
# Scalar API Reference è‡ªå®šä¹‰é…ç½®

# UI ä¸»é¢˜
theme: purple  # purple, blue, green, default

# å¸ƒå±€
layout: modern  # modern, classic

# ä¾§è¾¹æ 
sidebar:
  enabled: true
  defaultOpen: true
  showOperations: true

# é¡¶éƒ¨å¯¼èˆª
navbar:
  logo:
    url: /static/logo.png
    alt: arXiv Paper Curator
  title: arXiv Paper Curator API
  links:
    - text: GitHub
      url: https://github.com/jamwithai/arxiv-paper-curator
    - text: Blog
      url: https://jamwithai.substack.com
    - text: Gradio UI
      url: http://localhost:7861

# ä»£ç ç¤ºä¾‹
codeExamples:
  languages:
    - shell  # cURL
    - python
    - javascript
    - go
    - php
  defaultLanguage: shell

# æœç´¢
search:
  enabled: true
  hotkey: "/"

# æ“ä½œæ’åº
operations:
  sortBy: path  # path, method, alpha

# æ¨¡å‹æ˜¾ç¤º
models:
  show: true
  defaultExpanded: false

# Try It Out åŠŸèƒ½
tryItOut:
  enabled: true
  proxy: http://api:8000
  corsProxy: false

# è‡ªå®šä¹‰CSSï¼ˆå¯é€‰ï¼‰
customCss: |
  /* è‡ªå®šä¹‰æ ·å¼ */
  .scalar-api-reference {
    --scalar-color-1: #8b5cf6;  /* ç´«è‰²ä¸»é¢˜ */
  }

# è‡ªå®šä¹‰JavaScriptï¼ˆå¯é€‰ï¼‰
customJs: |
  // è‡ªå®šä¹‰è¡Œä¸º
  console.log('Scalar API Reference loaded');

# è®¤è¯ï¼ˆæœªæ¥ä½¿ç”¨ï¼‰
authentication:
  type: apiKey
  in: header
  name: X-API-Key
  placeholder: sk-xxxxxxxxxxxxxxxx

# æœåŠ¡å™¨é€‰æ‹©
servers:
  - url: http://localhost:8000
    description: Development (Local)
  - url: http://api:8000
    description: Development (Docker)
```

---

### æ­¥éª¤ 3.3: å¯åŠ¨ Scalar æœåŠ¡

**è„šæœ¬**: `scripts/start_scalar.sh`

```bash
#!/bin/bash
# scripts/start_scalar.sh

set -e

echo "ğŸš€ Starting Scalar API Documentation..."

# 1. ç¡®ä¿ API æœåŠ¡è¿è¡Œ
echo "ğŸ“¡ Checking API service..."
if docker compose ps api | grep -q "Up"; then
    echo "âœ… API service is running"
else
    echo "ğŸ”„ Starting API service..."
    docker compose up -d api
    echo "â³ Waiting for API to be healthy..."
    sleep 15
fi

# 2. éªŒè¯ OpenAPI è§„èŒƒå¯è®¿é—®
echo "ğŸ” Verifying OpenAPI spec..."
if curl -f -s http://localhost:8000/openapi.json > /dev/null; then
    echo "âœ… OpenAPI spec is accessible"
else
    echo "âŒ Cannot access OpenAPI spec at http://localhost:8000/openapi.json"
    exit 1
fi

# 3. å¯åŠ¨ Scalar æœåŠ¡
echo "ğŸ³ Starting Scalar UI..."
docker compose up -d scalar

# 4. ç­‰å¾… Scalar å¥åº·æ£€æŸ¥
echo "â³ Waiting for Scalar to be ready..."
for i in {1..30}; do
    if curl -f -s http://localhost:7998 > /dev/null 2>&1; then
        echo "âœ… Scalar UI is ready!"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "âŒ Scalar UI failed to start"
        docker compose logs scalar
        exit 1
    fi
    sleep 1
done

# 5. æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo ""
echo "ğŸ“Š Service Status:"
docker compose ps | grep -E "api|scalar"

echo ""
echo "âœ¨ Scalar API Documentation is now available at:"
echo "   ğŸŒ http://localhost:7998"
echo ""
echo "ğŸ“š Other Documentation:"
echo "   ğŸ“– Swagger UI: http://localhost:8000/docs"
echo "   ğŸ“˜ ReDoc:      http://localhost:8000/redoc"
echo ""
echo "ğŸ¯ Quick Test:"
echo "   curl http://localhost:7998"
```

**è¿è¡Œè„šæœ¬**:
```bash
chmod +x scripts/start_scalar.sh
./scripts/start_scalar.sh
```

---

### æ­¥éª¤ 3.4: éªŒè¯ Scalar é›†æˆ

**æµ‹è¯•æ¸…å•**: `scripts/test_scalar.sh`

```bash
#!/bin/bash
# scripts/test_scalar.sh

echo "ğŸ§ª Testing Scalar Integration..."

# Test 1: Scalar UI å¯è®¿é—®
echo "Test 1: Scalar UI accessibility..."
if curl -f -s http://localhost:7998 > /dev/null; then
    echo "âœ… PASS: Scalar UI is accessible"
else
    echo "âŒ FAIL: Scalar UI is not accessible"
    exit 1
fi

# Test 2: OpenAPI spec å¯è®¿é—®
echo "Test 2: OpenAPI spec accessibility..."
if curl -f -s http://localhost:8000/openapi.json > /dev/null; then
    echo "âœ… PASS: OpenAPI spec is accessible"
else
    echo "âŒ FAIL: OpenAPI spec is not accessible"
    exit 1
fi

# Test 3: Scalar å¯ä»¥è·å– spec
echo "Test 3: Scalar fetches OpenAPI spec..."
SPEC_URL=$(docker compose exec -T scalar env | grep SPEC_URL)
if [ -n "$SPEC_URL" ]; then
    echo "âœ… PASS: SPEC_URL is configured: $SPEC_URL"
else
    echo "âŒ FAIL: SPEC_URL is not configured"
    exit 1
fi

# Test 4: æ‰€æœ‰ç«¯ç‚¹åœ¨ Scalar ä¸­å¯è§
echo "Test 4: All endpoints visible in Scalar..."
ENDPOINTS_COUNT=$(curl -s http://localhost:8000/openapi.json | jq '.paths | length')
if [ "$ENDPOINTS_COUNT" -eq 6 ]; then
    echo "âœ… PASS: All 6 endpoints are defined"
else
    echo "âš ï¸  WARNING: Expected 6 endpoints, found $ENDPOINTS_COUNT"
fi

# Test 5: Scalar ä»£ç†åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
echo "Test 5: Testing Scalar proxy (if enabled)..."
if curl -f -s -X POST http://localhost:7998/proxy/api/v1/health > /dev/null 2>&1; then
    echo "âœ… PASS: Scalar proxy is working"
else
    echo "âš ï¸  INFO: Scalar proxy not enabled or not working (OK if disabled)"
fi

echo ""
echo "âœ… All critical tests passed!"
echo "ğŸŒ Open http://localhost:7998 to view Scalar UI"
```

---

## ğŸ“š Day 5-6: æ–‡æ¡£è´¨é‡æå‡

### æ­¥éª¤ 5.1: æ·»åŠ ä»£ç ç¤ºä¾‹åˆ°ç«¯ç‚¹

**æ–‡ä»¶**: `src/routers/hybrid_search.py`

**å¢å¼ºç«¯ç‚¹æ–‡æ¡£**:
```python
# src/routers/hybrid_search.py

@router.post(
    "/",
    response_model=SearchResponse,
    operation_id="hybrid_search_papers",
    summary="Search papers with hybrid retrieval",
    description="""
## ğŸ” Hybrid Search

Search academic papers using **BM25 (keyword)** + **Vector Similarity** with Reciprocal Rank Fusion.

### How It Works

1. **BM25 Search**: Traditional keyword matching on paper text
2. **Vector Search**: Semantic similarity using Jina embeddings (1024-dim)
3. **RRF Fusion**: Combines both results using Reciprocal Rank Fusion algorithm

### Search Modes

- `use_hybrid=true`: BM25 + Vector (recommended for best results)
- `use_hybrid=false`: BM25 only (faster, good for exact keyword matching)

### Filtering

- **Categories**: Filter by arXiv categories (e.g., `["cs.AI", "cs.LG"]`)
- **Latest Papers**: Sort by publication date instead of relevance
- **Min Score**: Set minimum relevance threshold

### Examples

#### Basic Search
```json
{
  "query": "transformer attention mechanism",
  "size": 10,
  "use_hybrid": true
}
```

#### Advanced Filtering
```json
{
  "query": "few-shot learning",
  "size": 20,
  "categories": ["cs.AI", "cs.LG"],
  "latest_papers": true,
  "min_score": 0.5
}
```

### Response Structure

Each hit contains:
- Paper metadata (title, authors, abstract)
- Matched chunk text (with highlights)
- Relevance score
- Section name
- PDF URL

### Performance

- Average latency: 200-500ms
- Supports pagination (use `from` parameter)
- Cached at OpenSearch level

### Use Cases

âœ… Literature review preparation
âœ… Finding similar papers
âœ… Topic exploration
âœ… Citation discovery
    """,
    responses={
        200: {
            "description": "Successful search with results",
            "content": {
                "application/json": {
                    "examples": {
                        "hybrid_search": {
                            "summary": "Hybrid Search Results",
                            "value": {
                                "query": "transformer attention mechanism",
                                "total": 45,
                                "hits": [
                                    {
                                        "arxiv_id": "1706.03762",
                                        "title": "Attention is All You Need",
                                        "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
                                        "abstract": "The dominant sequence transduction models...",
                                        "published_date": "2017-06-12",
                                        "pdf_url": "https://arxiv.org/pdf/1706.03762.pdf",
                                        "score": 15.234,
                                        "chunk_text": "The Transformer uses multi-head self-attention to allow the model to jointly attend to information from different representation subspaces.",
                                        "chunk_id": "1706.03762_chunk_42",
                                        "section_name": "3.2 Multi-Head Attention",
                                        "highlights": {
                                            "chunk_text": ["The <em>Transformer</em> uses multi-head self-<em>attention</em>"]
                                        }
                                    }
                                ],
                                "size": 10,
                                "from": 0,
                                "search_mode": "hybrid"
                            }
                        },
                        "no_results": {
                            "summary": "No Results Found",
                            "value": {
                                "query": "quantum entanglement in cooking",
                                "total": 0,
                                "hits": [],
                                "size": 10,
                                "from": 0,
                                "search_mode": "bm25"
                            }
                        }
                    }
                }
            }
        },
        503: {
            "description": "Search service unavailable",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Search service is currently unavailable"
                    }
                }
            }
        }
    },
    tags=["hybrid-search"]
)
async def hybrid_search(...):
    # ... implementation ...
```

---

### æ­¥éª¤ 5.2: åˆ›å»ºå¿«é€Ÿå¼€å§‹æŒ‡å—

**æ–‡ä»¶**: `docs/QUICKSTART.md`

```markdown
# ğŸš€ Quick Start Guide

Get started with the arXiv Paper Curator API in 5 minutes.

## Prerequisites

- Docker Desktop running
- API services started: `docker compose up -d`
- Scalar UI available at http://localhost:7998

## Step 1: Health Check

Verify all services are running:

\`\`\`bash
curl http://localhost:8000/api/v1/health | jq
\`\`\`

Expected response:
\`\`\`json
{
  "status": "ok",
  "services": {
    "database": {"status": "healthy"},
    "opensearch": {"status": "healthy"},
    "ollama": {"status": "healthy"}
  }
}
\`\`\`

## Step 2: Search Papers

Find papers about transformers:

\`\`\`bash
curl -X POST http://localhost:8000/api/v1/hybrid-search/ \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "transformer architecture",
    "size": 5,
    "use_hybrid": true
  }' | jq '.hits[0].title'
\`\`\`

## Step 3: Ask a Question (Basic RAG)

Get a quick answer:

\`\`\`bash
curl -X POST http://localhost:8000/api/v1/ask \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "What are transformers?",
    "top_k": 3,
    "use_hybrid": true
  }' | jq '.answer'
\`\`\`

## Step 4: Streaming Response

Real-time answer generation:

\`\`\`bash
curl -N -X POST http://localhost:8000/api/v1/stream \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "Explain attention mechanism",
    "top_k": 3
  }'
\`\`\`

## Step 5: Agentic RAG (Advanced)

Intelligent retrieval with reasoning:

\`\`\`bash
curl -X POST http://localhost:8000/api/v1/ask-agentic \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "Latest developments in vision transformers",
    "top_k": 5,
    "use_hybrid": true
  }' | jq '{answer, reasoning_steps, trace_id}'
\`\`\`

## Step 6: Submit Feedback

Rate the answer quality:

\`\`\`bash
# Get trace_id from Step 5 response
curl -X POST http://localhost:8000/api/v1/feedback \\
  -H "Content-Type: application/json" \\
  -d '{
    "trace_id": "YOUR_TRACE_ID_HERE",
    "score": 1.0,
    "comment": "Excellent answer!"
  }'
\`\`\`

## Next Steps

- ğŸ“– Explore Scalar UI: http://localhost:7998
- ğŸ¨ Try Gradio interface: http://localhost:7861
- ğŸ“Š View Langfuse traces: http://localhost:3000
- ğŸ“š Read full API docs: [API_DOCUMENTATION.md](../API_DOCUMENTATION.md)

## Python Client Example

\`\`\`python
import httpx
import asyncio

async def main():
    async with httpx.AsyncClient() as client:
        # Ask a question
        response = await client.post(
            "http://localhost:8000/api/v1/ask-agentic",
            json={
                "query": "What is self-attention?",
                "top_k": 3
            }
        )
        result = response.json()

        print(f"Answer: {result['answer']}")
        print(f"\\nReasoning:")
        for step in result['reasoning_steps']:
            print(f"  - {step}")

asyncio.run(main())
\`\`\`

## Troubleshooting

### API not responding
\`\`\`bash
docker compose ps
docker compose logs api
\`\`\`

### OpenSearch connection failed
\`\`\`bash
curl http://localhost:9200/_cluster/health
\`\`\`

### Ollama model not loaded
\`\`\`bash
docker compose exec ollama ollama list
\`\`\`

## Support

- GitHub Issues: https://github.com/jamwithai/arxiv-paper-curator/issues
- Blog: https://jamwithai.substack.com
\`\`\`

---

### æ­¥éª¤ 5.3: æ·»åŠ é”™è¯¯å“åº”æ–‡æ¡£

**é€šç”¨é”™è¯¯å¤„ç†å™¨**: `src/main.py`

```python
# src/main.py (æ·»åŠ åˆ° app åˆ›å»ºå)

from fastapi import Request, status
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel

class ErrorResponse(BaseModel):
    """Standard error response model"""
    error: str = Field(..., description="Error type")
    message: str = Field(..., description="Human-readable error message")
    detail: Optional[dict] = Field(None, description="Additional error details")
    trace_id: Optional[str] = Field(None, description="Trace ID for debugging")

# 422 Validation Error Handler
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle Pydantic validation errors"""
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={
            "error": "ValidationError",
            "message": "Request validation failed",
            "detail": exc.errors(),
            "body": exc.body
        }
    )

# 500 Internal Server Error Handler
@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected errors"""
    logger.error(f"Unexpected error: {exc}", exc_info=True)
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "InternalServerError",
            "message": "An unexpected error occurred",
            "detail": str(exc) if app.state.settings.debug else "Contact support"
        }
    )
```

**æ›´æ–°ç«¯ç‚¹é”™è¯¯å“åº”**:
```python
# src/routers/agentic_ask.py

@router.post(
    "/ask-agentic",
    response_model=AgenticAskResponse,
    responses={
        200: {"description": "Successful response with answer"},
        422: {
            "description": "Validation error or out-of-scope query",
            "model": ErrorResponse,
            "content": {
                "application/json": {
                    "examples": {
                        "out_of_scope": {
                            "summary": "Out of Scope Query",
                            "value": {
                                "error": "ValidationError",
                                "message": "Query is outside research paper scope",
                                "detail": {
                                    "guardrail_score": 35,
                                    "threshold": 60,
                                    "reason": "Query appears to be about weather, not academic research"
                                }
                            }
                        },
                        "invalid_request": {
                            "summary": "Invalid Request Parameters",
                            "value": {
                                "error": "ValidationError",
                                "message": "Request validation failed",
                                "detail": [
                                    {
                                        "loc": ["body", "top_k"],
                                        "msg": "ensure this value is less than or equal to 10",
                                        "type": "value_error.number.not_le"
                                    }
                                ]
                            }
                        }
                    }
                }
            }
        },
        500: {
            "description": "Internal server error",
            "model": ErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "error": "InternalServerError",
                        "message": "LLM service unavailable",
                        "detail": {
                            "service": "ollama",
                            "status": "connection_timeout"
                        }
                    }
                }
            }
        },
        503: {
            "description": "Service unavailable",
            "model": ErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "error": "ServiceUnavailable",
                        "message": "OpenSearch cluster is down",
                        "detail": "Retry after 30 seconds"
                    }
                }
            }
        }
    }
)
async def ask_agentic(...):
    ...
```

---

## ğŸ§ª Day 7-8: æµ‹è¯•å’Œä¼˜åŒ–

### æµ‹è¯•å¥—ä»¶

**åˆ›å»ºå®Œæ•´æµ‹è¯•**: `tests/test_scalar_integration.py`

```python
# tests/test_scalar_integration.py
import pytest
import httpx
import json
from typing import AsyncGenerator

@pytest.fixture
async def api_client() -> AsyncGenerator[httpx.AsyncClient, None]:
    """Async HTTP client for API testing"""
    async with httpx.AsyncClient(base_url="http://localhost:8000") as client:
        yield client

@pytest.fixture
async def scalar_client() -> AsyncGenerator[httpx.AsyncClient, None]:
    """Async HTTP client for Scalar UI testing"""
    async with httpx.AsyncClient(base_url="http://localhost:7998") as client:
        yield client


class TestScalarUI:
    """Test Scalar UI accessibility and configuration"""

    async def test_scalar_ui_accessible(self, scalar_client):
        """Scalar UI should be accessible"""
        response = await scalar_client.get("/")
        assert response.status_code == 200
        assert "scalar" in response.text.lower()

    async def test_scalar_loads_openapi_spec(self, scalar_client):
        """Scalar should load OpenAPI spec from FastAPI"""
        # This tests that Scalar can fetch the spec
        response = await scalar_client.get("/")
        html = response.text
        assert "openapi.json" in html or "specification" in html.lower()


class TestOpenAPISpec:
    """Test OpenAPI specification quality"""

    async def test_openapi_spec_valid(self, api_client):
        """OpenAPI spec should be valid JSON"""
        response = await api_client.get("/openapi.json")
        assert response.status_code == 200
        spec = response.json()
        assert "openapi" in spec
        assert spec["openapi"].startswith("3.")

    async def test_all_endpoints_documented(self, api_client):
        """All 6 endpoints should be in OpenAPI spec"""
        response = await api_client.get("/openapi.json")
        spec = response.json()
        paths = spec["paths"]

        # Expected endpoints
        assert "/api/v1/health" in paths
        assert "/api/v1/hybrid-search/" in paths
        assert "/api/v1/ask" in paths
        assert "/api/v1/stream" in paths
        assert "/api/v1/ask-agentic" in paths
        assert "/api/v1/feedback" in paths

    async def test_all_endpoints_have_examples(self, api_client):
        """All POST endpoints should have request examples"""
        response = await api_client.get("/openapi.json")
        spec = response.json()

        for path, methods in spec["paths"].items():
            for method, details in methods.items():
                if method == "post":
                    # Check for examples in request body
                    if "requestBody" in details:
                        content = details["requestBody"]["content"]["application/json"]
                        assert "examples" in content or "example" in content.get("schema", {}), \
                            f"Missing examples in {method.upper()} {path}"

    async def test_all_endpoints_have_operation_ids(self, api_client):
        """All endpoints should have unique operation IDs"""
        response = await api_client.get("/openapi.json")
        spec = response.json()

        operation_ids = set()
        for path, methods in spec["paths"].items():
            for method, details in methods.items():
                assert "operationId" in details, \
                    f"Missing operationId in {method.upper()} {path}"

                op_id = details["operationId"]
                assert op_id not in operation_ids, \
                    f"Duplicate operationId: {op_id}"
                operation_ids.add(op_id)


class TestAPIThroughScalar:
    """Test API calls through Scalar proxy (if enabled)"""

    async def test_health_check(self, api_client):
        """Health check should work"""
        response = await api_client.get("/api/v1/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] in ["ok", "degraded"]

    async def test_hybrid_search_example(self, api_client):
        """Hybrid search example should work"""
        response = await api_client.post(
            "/api/v1/hybrid-search/",
            json={
                "query": "transformer",
                "size": 5,
                "use_hybrid": True
            }
        )
        assert response.status_code == 200
        data = response.json()
        assert "hits" in data
        assert data["query"] == "transformer"

    async def test_ask_example(self, api_client):
        """Basic RAG example should work"""
        response = await api_client.post(
            "/api/v1/ask",
            json={
                "query": "What is attention?",
                "top_k": 1,
                "use_hybrid": False
            },
            timeout=30.0
        )
        assert response.status_code == 200
        data = response.json()
        assert "answer" in data
        assert "sources" in data

    @pytest.mark.asyncio
    async def test_stream_example(self, api_client):
        """Streaming RAG should work"""
        async with api_client.stream(
            "POST",
            "/api/v1/stream",
            json={"query": "test", "top_k": 1},
            timeout=30.0
        ) as response:
            assert response.status_code == 200
            assert response.headers["content-type"] == "text/plain; charset=utf-8"

            chunks_received = 0
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    chunks_received += 1
                    data = json.loads(line[6:])
                    assert isinstance(data, dict)

            assert chunks_received > 0, "No SSE events received"


class TestErrorResponses:
    """Test error handling and responses"""

    async def test_invalid_query_length(self, api_client):
        """Too short query should return 422"""
        response = await api_client.post(
            "/api/v1/ask",
            json={"query": "", "top_k": 3}
        )
        assert response.status_code == 422

    async def test_invalid_top_k(self, api_client):
        """Invalid top_k should return 422"""
        response = await api_client.post(
            "/api/v1/ask",
            json={"query": "test", "top_k": 100}  # max is 10
        )
        assert response.status_code == 422

    async def test_feedback_without_langfuse(self, api_client):
        """Feedback without trace_id should return error"""
        response = await api_client.post(
            "/api/v1/feedback",
            json={
                "trace_id": "invalid-trace",
                "score": 1.0
            }
        )
        # Should either work or return 503 if Langfuse disabled
        assert response.status_code in [200, 503, 500]


# Performance Tests
class TestPerformance:
    """Performance benchmarks"""

    async def test_health_check_latency(self, api_client):
        """Health check should be fast"""
        import time
        start = time.time()
        response = await api_client.get("/api/v1/health")
        latency = time.time() - start

        assert response.status_code == 200
        assert latency < 1.0, f"Health check too slow: {latency:.2f}s"

    async def test_openapi_spec_latency(self, api_client):
        """OpenAPI spec generation should be fast"""
        import time
        start = time.time()
        response = await api_client.get("/openapi.json")
        latency = time.time() - start

        assert response.status_code == 200
        assert latency < 0.5, f"OpenAPI spec too slow: {latency:.2f}s"
```

**è¿è¡Œæµ‹è¯•**:
```bash
# è¿è¡Œæ‰€æœ‰ Scalar é›†æˆæµ‹è¯•
uv run pytest tests/test_scalar_integration.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
uv run pytest tests/test_scalar_integration.py::TestOpenAPISpec -v

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
uv run pytest tests/test_scalar_integration.py --html=report.html
```

---

## ğŸ“– Day 9-10: éƒ¨ç½²å’Œæ–‡æ¡£

### æ›´æ–° README

**æ·»åŠ  Scalar éƒ¨åˆ†åˆ° README.md**:

```markdown
## ğŸ“š API Documentation

We provide **three ways** to explore our API:

### 1. ğŸ¨ Scalar API Reference (Recommended)

Modern, interactive API documentation with beautiful UI.

- **URL**: http://localhost:7998
- **Features**:
  - ğŸ¯ Try It Out with live API calls
  - ğŸ“ Code generation (Python, JavaScript, cURL)
  - ğŸ” Powerful search
  - ğŸ“± Mobile-friendly
  - ğŸ¨ Purple theme optimized for readability

### 2. ğŸ“– Swagger UI (FastAPI Default)

Classic OpenAPI documentation.

- **URL**: http://localhost:8000/docs
- **Features**: Interactive API testing, schema viewer

### 3. ğŸ“˜ ReDoc

Clean, three-panel API documentation.

- **URL**: http://localhost:8000/redoc
- **Features**: Search, deep linking, print-friendly

---

## ğŸš€ Quick Start with Scalar

1. **Start all services**:
   ```bash
   docker compose up -d
   ```

2. **Open Scalar UI**:
   ```
   http://localhost:7998
   ```

3. **Try your first API call**:
   - Navigate to `/api/v1/health`
   - Click "Try It Out"
   - Click "Send Request"
   - See the live response!

---

## ğŸ“Š Service URLs

| Service | URL | Description |
|---------|-----|-------------|
| **Scalar UI** | http://localhost:7998 | Modern API docs â­ |
| **API** | http://localhost:8000 | FastAPI application |
| **Swagger UI** | http://localhost:8000/docs | Interactive API docs |
| **ReDoc** | http://localhost:8000/redoc | Clean API docs |
| **Gradio** | http://localhost:7861 | Chat interface |
| **Langfuse** | http://localhost:3000 | Tracing dashboard |
| **OpenSearch** | http://localhost:5601 | Search admin |
| **Airflow** | http://localhost:8080 | Workflow management |
```

---

### åˆ›å»ºç”¨æˆ·æŒ‡å—

**æ–‡ä»¶**: `docs/SCALAR_USER_GUIDE.md`

```markdown
# Scalar UI User Guide

## ğŸ¯ Overview

Scalar provides a beautiful, modern interface for exploring the arXiv Paper Curator API.

## ğŸ“ Navigation

### Sidebar

The left sidebar shows all API endpoints grouped by tags:

- **Health**: System monitoring
- **hybrid-search**: Document search
- **ask**: Basic RAG
- **stream**: Streaming RAG
- **agentic-rag**: Intelligent RAG

### Top Bar

- **Search** (press `/`): Find endpoints, schemas, or text
- **Server**: Select API server (development/production)
- **Theme**: Purple (default), Blue, Green

## ğŸš€ Making API Calls

### Step 1: Select an Endpoint

Click on any endpoint in the sidebar (e.g., `POST /api/v1/ask`)

### Step 2: View Request Schema

Scroll to "Request Body" section to see:
- Required parameters
- Parameter types
- Descriptions
- Examples

### Step 3: Try It Out

1. Click "Try It Out" button
2. Modify the request JSON (or use provided example)
3. Click "Send Request"
4. View the response below

### Example: Ask a Question

```json
{
  "query": "What are transformers?",
  "top_k": 3,
  "use_hybrid": true,
  "model": "llama3.2:1b"
}
```

## ğŸ“ Code Generation

### Generate Client Code

1. Make a successful API call
2. Click "Code" tab above the request
3. Select language:
   - Shell (cURL)
   - Python
   - JavaScript
   - Go
   - PHP

### Example Generated Code

**Python**:
```python
import httpx

response = httpx.post(
    "http://localhost:8000/api/v1/ask",
    json={
        "query": "What are transformers?",
        "top_k": 3
    }
)
print(response.json())
```

## ğŸ” Advanced Features

### Search

Press `/` or click search box:
- Search endpoint names: "health", "search", "ask"
- Search by tag: "agentic-rag"
- Search in descriptions: "streaming"

### Schemas

View data models:
1. Scroll to "Schemas" section (bottom of sidebar)
2. Click on any schema (e.g., `AskRequest`)
3. See all fields with types and descriptions

### Request History

Scalar remembers your recent requests in browser localStorage.

## ğŸ¨ Customization

### Change Theme

Click theme selector (top right):
- Purple (default)
- Blue
- Green
- Default

### Change Server

Click server dropdown (top):
- Development (http://localhost:8000)
- Docker Internal (http://api:8000)

## ğŸ’¡ Tips & Tricks

### 1. Use Examples

Every endpoint has pre-filled examples. Click "Use Example" to autofill.

### 2. Keyboard Shortcuts

- `/` - Open search
- `Esc` - Close modals
- `Ctrl/Cmd + K` - Command palette

### 3. Copy Response

Click "Copy" icon in response section to copy JSON.

### 4. Authentication (Future)

When API authentication is enabled:
1. Click "Auth" button (top right)
2. Enter your API key
3. Key is saved for all requests

## ğŸ› Troubleshooting

### Can't Send Requests

**Problem**: "Try It Out" doesn't work

**Solutions**:
1. Check API is running: `curl http://localhost:8000/health`
2. Check CORS settings
3. Try direct API call with cURL to isolate issue

### No Endpoints Visible

**Problem**: Sidebar is empty

**Solutions**:
1. Check OpenAPI spec loads: `curl http://localhost:8000/openapi.json`
2. Refresh browser (Ctrl+F5)
3. Clear browser cache
4. Check Scalar container logs: `docker compose logs scalar`

### Slow Response Times

**Problem**: API calls take too long

**Solutions**:
1. Use smaller `top_k` (e.g., 3 instead of 10)
2. Disable hybrid search for faster results
3. Check service health: GET `/api/v1/health`

## ğŸ“ Support

- GitHub Issues: https://github.com/jamwithai/arxiv-paper-curator/issues
- Documentation: [API_DOCUMENTATION.md](../API_DOCUMENTATION.md)
- Blog: https://jamwithai.substack.com
```

---

## âœ… éªŒæ”¶æ¸…å•

**å®Œæ•´éªŒæ”¶**: `scripts/acceptance_test.sh`

```bash
#!/bin/bash
# scripts/acceptance_test.sh

echo "ğŸ¯ Running Acceptance Tests for Scalar Integration..."

PASS=0
FAIL=0

function test_case() {
    echo ""
    echo "Testing: $1"
    if eval "$2"; then
        echo "âœ… PASS"
        ((PASS++))
    else
        echo "âŒ FAIL"
        ((FAIL++))
    fi
}

# Test 1: Scalar UI Accessible
test_case "Scalar UI accessible at :7998" \
    "curl -f -s http://localhost:7998 > /dev/null"

# Test 2: OpenAPI Spec Valid
test_case "OpenAPI spec is valid JSON" \
    "curl -s http://localhost:8000/openapi.json | jq . > /dev/null"

# Test 3: All 6 Endpoints Present
test_case "All 6 endpoints documented" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.paths | length') -eq 6 ]]"

# Test 4: All Endpoints Have Examples
test_case "All POST endpoints have examples" \
    "curl -s http://localhost:8000/openapi.json | jq '[.paths[][] | select(.requestBody) | .requestBody.content.\"application/json\" | select(.examples == null and .schema.examples == null)] | length' | grep -q '^0$'"

# Test 5: All Endpoints Have Operation IDs
test_case "All endpoints have operation IDs" \
    "curl -s http://localhost:8000/openapi.json | jq '[.paths[][] | select(.operationId == null)] | length' | grep -q '^0$'"

# Test 6: SSE Endpoint Defined
test_case "/stream endpoint has SSE documentation" \
    "curl -s http://localhost:8000/openapi.json | jq '.paths[\"/api/v1/stream\"].post.responses.\"200\".content.\"text/event-stream\"' | grep -q 'example'"

# Test 7: Error Responses Documented
test_case "Error responses (422, 500) documented" \
    "curl -s http://localhost:8000/openapi.json | jq '[.paths[][] | select(.responses.\"422\" or .responses.\"500\")] | length' | grep -qv '^0$'"

# Test 8: Tags Defined
test_case "OpenAPI tags defined" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.tags | length') -ge 5 ]]"

# Test 9: Servers Defined
test_case "Servers section defined" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.servers | length') -ge 1 ]]"

# Test 10: API Health Check Works
test_case "API health check returns 200" \
    "curl -f -s http://localhost:8000/api/v1/health > /dev/null"

# Summary
echo ""
echo "======================================"
echo "Acceptance Test Results"
echo "======================================"
echo "âœ… Passed: $PASS"
echo "âŒ Failed: $FAIL"
echo "Total: $((PASS + FAIL))"
echo "======================================"

if [ $FAIL -eq 0 ]; then
    echo "ğŸ‰ All acceptance tests passed!"
    exit 0
else
    echo "âš ï¸  Some acceptance tests failed!"
    exit 1
fi
```

**è¿è¡ŒéªŒæ”¶æµ‹è¯•**:
```bash
chmod +x scripts/acceptance_test.sh
./scripts/acceptance_test.sh
```

---

## ğŸ“¦ å®Œæ•´æ–‡ä»¶æ¸…å•

### æ–°å¢æ–‡ä»¶

```
13 arxiv-paper-curator/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ validate_openapi.sh         # OpenAPI éªŒè¯è„šæœ¬
â”‚   â”œâ”€â”€ start_scalar.sh              # Scalar å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ test_scalar.sh               # Scalar æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ acceptance_test.sh           # éªŒæ”¶æµ‹è¯•è„šæœ¬
â”œâ”€â”€ .scalar/
â”‚   â””â”€â”€ config.yml                   # Scalar é…ç½®æ–‡ä»¶
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_scalar_integration.py   # é›†æˆæµ‹è¯•
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ QUICKSTART.md                # å¿«é€Ÿå¼€å§‹æŒ‡å—
â”‚   â””â”€â”€ SCALAR_USER_GUIDE.md         # ç”¨æˆ·æŒ‡å—
â””â”€â”€ SCALAR_IMPLEMENTATION_GUIDE.md   # æœ¬æ–‡ä»¶
```

### ä¿®æ”¹æ–‡ä»¶

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                      # å¢å¼º FastAPI å…ƒæ•°æ®
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ ask.py                   # ä¿®å¤ /stream å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py         # å¢å¼ºæ–‡æ¡£
â”‚   â”‚   â””â”€â”€ agentic_ask.py           # å¢å¼ºæ–‡æ¡£
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ api/
â”‚           â”œâ”€â”€ ask.py               # å¢å¼º examples
â”‚           â””â”€â”€ search.py            # å¢å¼º examples
â”œâ”€â”€ compose.yml                      # æ·»åŠ  Scalar æœåŠ¡
â””â”€â”€ README.md                        # æ·»åŠ  Scalar è¯´æ˜
```

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### æŠ€æœ¯æŒ‡æ ‡

- âœ… OpenAPI éªŒè¯: 0 errors
- âœ… Scalar UI è®¿é—®å»¶è¿Ÿ: < 1s
- âœ… æ‰€æœ‰ 6 ä¸ªç«¯ç‚¹å¯è§
- âœ… SSE æµå¼æ–‡æ¡£å®Œæ•´
- âœ… æ‰€æœ‰ç«¯ç‚¹æœ‰ examples
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡

### ç”¨æˆ·ä½“éªŒ

- âœ… 5 åˆ†é’Ÿå†…å®Œæˆé¦–æ¬¡ API è°ƒç”¨
- âœ… æ–‡æ¡£æ˜“äºæœç´¢
- âœ… ä»£ç ç”ŸæˆåŠŸèƒ½å¯ç”¨
- âœ… ç§»åŠ¨ç«¯å¯è®¿é—®

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹ [SCALAR_MIGRATION_PLAN.md](SCALAR_MIGRATION_PLAN.md) çš„é£é™©åˆ†æ
2. è¿è¡Œè¯Šæ–­è„šæœ¬: `./scripts/test_scalar.sh`
3. æŸ¥çœ‹æ—¥å¿—: `docker compose logs scalar`
4. æäº¤ Issue: GitHub Issues

---

**å®æ–½æ„‰å¿«ï¼ğŸš€**
