# Scalar API æ–‡æ¡£è¿ç§»å®æ–½æŒ‡å— (ä¿®è®¢ç‰ˆ V2)

> **ç‰ˆæœ¬**: 2.0
> **åˆ›å»ºæ—¥æœŸ**: 2025-12-07
> **çŠ¶æ€**: Ready for Implementation
> **é£é™©ç­‰çº§**: ğŸŸ¡ ä¸­ç­‰é£é™©

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### åŸè®¡åˆ’çš„å…³é”®é—®é¢˜

ç»è¿‡æ·±å…¥ä»£ç å®¡æŸ¥å’ŒæŠ€æœ¯éªŒè¯,åŸ V1 è®¡åˆ’å­˜åœ¨ä»¥ä¸‹**ä¸¥é‡é—®é¢˜**:

| é—®é¢˜ | ä¸¥é‡æ€§ | å½±å“ |
|------|--------|------|
| âŒ **Scalar Docker é•œåƒä¸å­˜åœ¨** | ğŸ”´ è‡´å‘½ | æ— æ³•å¯åŠ¨æœåŠ¡ |
| âŒ **SSE ç«¯ç‚¹æ— æ³•æ­£ç¡®æ–‡æ¡£åŒ–** | ğŸŸ  é«˜ | æ ¸å¿ƒåŠŸèƒ½ç¼ºå¤± |
| âŒ **ç¼ºå°‘æ€§èƒ½åŸºçº¿æµ‹è¯•** | ğŸŸ¡ ä¸­ | æ— æ³•è¯„ä¼°å½±å“ |
| âŒ **å®‰å…¨é£é™©è¯„ä¼°ä¸è¶³** | ğŸŸ  é«˜ | æ½œåœ¨ä¿¡æ¯æ³„éœ² |
| âš ï¸ **è¿‡åº¦ä¾èµ–æœªéªŒè¯çš„å·¥å…·** | ğŸŸ¡ ä¸­ | å®æ–½é£é™©é«˜ |

### ä¿®è®¢åçš„æ–¹æ¡ˆ

**æ ¸å¿ƒå˜æ›´**:

1. âœ… **ä½¿ç”¨ Scalar é™æ€ HTML ç”Ÿæˆæ–¹æ¡ˆ** (å–ä»£ Docker å®¹å™¨)
2. âœ… **SSE ç«¯ç‚¹é‡‡ç”¨é™çº§æ–‡æ¡£ç­–ç•¥** (ä¿ç•™åŠŸèƒ½,ä¼˜åŒ–æ–‡æ¡£)
3. âœ… **å»ºç«‹å®Œæ•´çš„æ€§èƒ½åŸºçº¿å’Œç›‘æ§**
4. âœ… **å¢åŠ å®‰å…¨å®¡è®¡å’Œè„±æ•æ£€æŸ¥**
5. âœ… **æ‰€æœ‰æ­¥éª¤éƒ½æœ‰å¯æ‰§è¡Œçš„éªŒè¯ä»£ç **

---

## ğŸ¯ ä¿®è®¢åçš„ç›®æ ‡

### æŠ€æœ¯ç›®æ ‡

- [x] ç”Ÿæˆç¬¦åˆ OpenAPI 3.0.2 è§„èŒƒçš„ API æ–‡æ¡£
- [x] ä½¿ç”¨ Scalar ä½œä¸ºç°ä»£åŒ–æ–‡æ¡£ UI (é™æ€æ‰˜ç®¡)
- [x] ä¿æŒæ‰€æœ‰ç°æœ‰ API åŠŸèƒ½ä¸å˜
- [x] æ€§èƒ½æŸè€— < 5%
- [x] é›¶æˆæœ¬æ–¹æ¡ˆ (å¼€æºå·¥å…·)

### éç›®æ ‡ (æ˜ç¡®æ’é™¤)

- âŒ ä¸ä½¿ç”¨ Scalar Cloud SaaS (é¿å…æ•°æ®ä¸Šä¼ )
- âŒ ä¸å¼•å…¥ API Gateway (é¿å…æ€§èƒ½æŸè€—)
- âŒ ä¸ä¿®æ”¹ç°æœ‰ API è¡Œä¸º (ä»…æ–‡æ¡£å¢å¼º)

---

## ğŸ“… ä¿®è®¢åçš„å®æ–½è®¡åˆ’

### æ€»æ—¶é•¿: 7 ä¸ªå·¥ä½œæ—¥ (å‹ç¼©ç‰ˆ)

```
Day 1: ç¯å¢ƒå‡†å¤‡å’ŒåŸºçº¿æµ‹è¯•         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 2: OpenAPI è§„èŒƒå¢å¼ºå’ŒéªŒè¯     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 3: Scalar é™æ€ç«™ç‚¹ç”Ÿæˆ        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 4: SSE ç«¯ç‚¹ä¼˜åŒ–å’Œæµ‹è¯•         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 5: å®‰å…¨å®¡è®¡å’Œè„±æ•             [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 6: å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œ           [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
Day 7: æ–‡æ¡£å’ŒéªŒæ”¶                 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 8h
```

---

## ğŸ”§ Day 1: ç¯å¢ƒå‡†å¤‡å’ŒåŸºçº¿æµ‹è¯•

### 1.1 å®‰è£…å¿…è¦å·¥å…·

```bash
# 1. å®‰è£… Scalar CLI (å·²å®‰è£…,éªŒè¯ç‰ˆæœ¬)
which scalar
# /opt/homebrew/bin/scalar

# 2. å®‰è£… OpenAPI éªŒè¯å·¥å…·
npm install -g @stoplight/spectral-cli

# 3. å®‰è£…æ€§èƒ½æµ‹è¯•å·¥å…·
pip install locust httpx

# 4. éªŒè¯å½“å‰ API è¿è¡ŒçŠ¶æ€
docker compose ps | grep api
# æœŸæœ›: rag-api   Up   (healthy)
```

### 1.2 å»ºç«‹æ€§èƒ½åŸºçº¿

**è„šæœ¬**: `scripts/baseline_performance.py`

```python
#!/usr/bin/env python3
"""
Performance baseline test for API before Scalar migration
è¿è¡Œå‰: docker compose up -d api
"""

import asyncio
import time
import statistics
from typing import List, Dict
import httpx
import json

BASE_URL = "http://localhost:8000"

async def test_endpoint_latency(endpoint: str, method: str = "GET", json_data: dict = None) -> float:
    """Measure single request latency"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        start = time.time()

        if method == "GET":
            response = await client.get(f"{BASE_URL}{endpoint}")
        else:
            response = await client.post(f"{BASE_URL}{endpoint}", json=json_data)

        latency = time.time() - start

        if response.status_code != 200:
            raise Exception(f"Request failed: {response.status_code}")

        return latency

async def benchmark_endpoint(
    endpoint: str,
    method: str = "GET",
    json_data: dict = None,
    iterations: int = 10
) -> Dict:
    """Run multiple iterations and collect stats"""
    latencies = []

    for i in range(iterations):
        try:
            latency = await test_endpoint_latency(endpoint, method, json_data)
            latencies.append(latency)
            await asyncio.sleep(0.5)  # Avoid overwhelming the server
        except Exception as e:
            print(f"  âŒ Iteration {i+1} failed: {e}")

    if not latencies:
        return {"error": "All requests failed"}

    return {
        "endpoint": endpoint,
        "method": method,
        "iterations": len(latencies),
        "min": min(latencies),
        "max": max(latencies),
        "mean": statistics.mean(latencies),
        "median": statistics.median(latencies),
        "stdev": statistics.stdev(latencies) if len(latencies) > 1 else 0,
        "p95": sorted(latencies)[int(len(latencies) * 0.95)] if len(latencies) > 1 else latencies[0],
    }

async def main():
    print("ğŸš€ Starting Performance Baseline Test...")
    print("=" * 60)

    # Test cases
    test_cases = [
        {
            "name": "Health Check",
            "endpoint": "/api/v1/health",
            "method": "GET",
        },
        {
            "name": "OpenAPI Spec",
            "endpoint": "/openapi.json",
            "method": "GET",
        },
        {
            "name": "Hybrid Search",
            "endpoint": "/api/v1/hybrid-search/",
            "method": "POST",
            "json": {
                "query": "transformer architecture",
                "size": 5,
                "use_hybrid": True
            }
        },
        {
            "name": "Basic RAG (BM25 only)",
            "endpoint": "/api/v1/ask",
            "method": "POST",
            "json": {
                "query": "What is attention mechanism?",
                "top_k": 3,
                "use_hybrid": False,
                "model": "llama3.2:1b"
            }
        },
    ]

    results = []

    for test in test_cases:
        print(f"\nğŸ“Š Testing: {test['name']}")
        print(f"   Endpoint: {test['method']} {test['endpoint']}")

        result = await benchmark_endpoint(
            endpoint=test['endpoint'],
            method=test['method'],
            json_data=test.get('json'),
            iterations=10
        )

        if "error" not in result:
            print(f"   âœ… Mean: {result['mean']*1000:.0f}ms | P95: {result['p95']*1000:.0f}ms | StDev: {result['stdev']*1000:.0f}ms")
        else:
            print(f"   âŒ {result['error']}")

        results.append({**test, **result})

    # Save results
    with open("baseline_performance.json", "w") as f:
        json.dump(results, f, indent=2)

    print("\n" + "=" * 60)
    print("âœ… Baseline test complete!")
    print("ğŸ“ Results saved to: baseline_performance.json")
    print("\nğŸ’¡ Summary:")

    for r in results:
        if "mean" in r:
            print(f"  {r['name']:30s} {r['mean']*1000:6.0f}ms (Â±{r['stdev']*1000:.0f}ms)")

if __name__ == "__main__":
    asyncio.run(main())
```

**è¿è¡ŒåŸºçº¿æµ‹è¯•**:

```bash
cd /path/to/arxiv-paper-curator
python scripts/baseline_performance.py
```

**é¢„æœŸè¾“å‡ºç¤ºä¾‹**:

```
============================================================
ğŸ“Š Testing: Health Check
   Endpoint: GET /api/v1/health
   âœ… Mean: 45ms | P95: 62ms | StDev: 12ms

ğŸ“Š Testing: OpenAPI Spec
   Endpoint: GET /openapi.json
   âœ… Mean: 234ms | P95: 298ms | StDev: 45ms

ğŸ“Š Testing: Hybrid Search
   Endpoint: POST /api/v1/hybrid-search/
   âœ… Mean: 387ms | P95: 512ms | StDev: 78ms

ğŸ“Š Testing: Basic RAG (BM25 only)
   Endpoint: POST /api/v1/ask
   âœ… Mean: 2834ms | P95: 3421ms | StDev: 412ms
============================================================
âœ… Baseline test complete!
ğŸ“ Results saved to: baseline_performance.json

ğŸ’¡ Summary:
  Health Check                       45ms (Â±12ms)
  OpenAPI Spec                      234ms (Â±45ms)
  Hybrid Search                     387ms (Â±78ms)
  Basic RAG (BM25 only)            2834ms (Â±412ms)
```

### 1.3 å¯¼å‡ºå½“å‰ OpenAPI è§„èŒƒ

```bash
# å¯åŠ¨ API (å¦‚æœæœªè¿è¡Œ)
docker compose up -d api

# ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡
sleep 10

# å¯¼å‡ºåŸå§‹ OpenAPI spec
curl -s http://localhost:8000/openapi.json | jq . > openapi_v1_original.json

# éªŒè¯åŸºæœ¬ç»“æ„
jq '.info.title, .openapi, (.paths | length)' openapi_v1_original.json
# è¾“å‡º:
# "arXiv Paper Curator API"
# "3.1.0"
# 6
```

### Day 1 éªŒæ”¶æ ‡å‡†

- [x] `baseline_performance.json` æ–‡ä»¶å·²ç”Ÿæˆ
- [x] æ‰€æœ‰ 4 ä¸ªç«¯ç‚¹çš„ P95 å»¶è¿Ÿ < 5000ms
- [x] `openapi_v1_original.json` å¯¼å‡ºæˆåŠŸ
- [x] OpenAPI version ä¸º `3.1.0` æˆ– `3.0.2`
- [x] è·¯å¾„æ•°é‡ä¸º 6

---

## ğŸ”§ Day 2: OpenAPI è§„èŒƒå¢å¼ºå’ŒéªŒè¯

### 2.1 å¢å¼º FastAPI åº”ç”¨å…ƒæ•°æ®

**æ–‡ä»¶**: `src/main.py`

**ä¿®æ”¹å†…å®¹**:

```python
# src/main.py (ç¬¬ 106-111 è¡Œ,æ›¿æ¢åŸæœ‰ FastAPI åˆå§‹åŒ–)

from fastapi.openapi.utils import get_openapi

app = FastAPI(
    title="arXiv Paper Curator API",
    description="""
# ğŸ“ Academic Research Assistant with RAG

A production-grade **Retrieval-Augmented Generation** system for academic papers from arXiv.

## âœ¨ Key Features

- **ğŸ” Hybrid Search**: BM25 keyword + Vector similarity (Jina 1024-dim)
- **ğŸ¤– Agentic RAG**: Intelligent retrieval with LangGraph decision-making
- **ğŸ“Š Real-time Tracing**: Langfuse observability for every request
- **âš¡ High Performance**: Redis caching with 6-hour TTL
- **ğŸ“¡ Streaming Support**: Server-Sent Events for real-time responses
- **ğŸ“± Mobile Access**: Telegram bot integration

## ğŸš€ Quick Start

1. **Health Check**: `GET /api/v1/health` - Verify all services
2. **Search Papers**: `POST /api/v1/hybrid-search/` - Find relevant papers
3. **Ask Questions**: `POST /api/v1/ask-agentic` - Get intelligent answers

## ğŸ—ï¸ Architecture

```
User Query â†’ Guardrail â†’ Hybrid Search â†’ Document Grading â†’ Answer Generation
                â†“                              â†“
            Out of Scope?              Not Relevant? â†’ Query Rewriting
```

## ğŸ”— Resources

- **Blog Series**: [The Mother of AI Projects](https://jamwithai.substack.com/p/the-mother-of-ai-project)
- **Source Code**: [GitHub Repository](https://github.com/Yemu-Yu/arxiv-paper-curator)
- **Gradio UI**: http://localhost:7861
- **Langfuse Dashboard**: http://localhost:3001

## ğŸ“ Support

For issues and feature requests, visit [GitHub Issues](https://github.com/Yemu-Yu/arxiv-paper-curator/issues).
    """,
    version=os.getenv("APP_VERSION", "0.1.0"),
    lifespan=lifespan,

    # è”ç³»ä¿¡æ¯
    contact={
        "name": "arXiv Paper Curator Team",
        "url": "https://github.com/Yemu-Yu/arxiv-paper-curator",
        "email": "yemu.yu@example.com"  # æ›¿æ¢ä¸ºå®é™…é‚®ç®±
    },

    # è®¸å¯è¯
    license_info={
        "name": "MIT License",
        "url": "https://github.com/Yemu-Yu/arxiv-paper-curator/blob/main/LICENSE"
    },

    # æœåŠ¡å™¨é…ç½® (Scalar ä¼šæ˜¾ç¤ºåœ¨ UI ä¸­)
    servers=[
        {
            "url": "http://localhost:8000",
            "description": "ğŸ› ï¸ Development Server (Local)"
        },
        {
            "url": "http://api:8000",
            "description": "ğŸ³ Docker Internal Network"
        }
    ],

    # Tags åˆ†ç»„ (ç”¨äº Scalar ä¾§è¾¹æ )
    openapi_tags=[
        {
            "name": "Health",
            "description": """
## ğŸ¥ System Health & Monitoring

Monitor the health of all backend services including:
- PostgreSQL database
- OpenSearch search engine
- Ollama LLM service
- Redis cache
- Langfuse tracing

**Use Case**: Include this endpoint in your monitoring/alerting system.
            """,
            "externalDocs": {
                "description": "Health Check Pattern",
                "url": "https://microservices.io/patterns/observability/health-check-api.html"
            }
        },
        {
            "name": "hybrid-search",
            "description": """
## ğŸ” Hybrid Document Search

Search academic papers using **BM25** (keyword) + **Vector Similarity** (semantic).

### How It Works

1. **BM25 Search**: Traditional keyword matching on paper text
2. **Vector Search**: Semantic similarity using Jina embeddings (1024-dim)
3. **RRF Fusion**: Combines both using Reciprocal Rank Fusion

### Best Practices

- Use `use_hybrid=true` for best results (combines keyword + semantic)
- Use `categories` filter to narrow down to specific arXiv categories
- Set `min_score` to filter low-relevance results

**Performance**: 200-500ms average latency.
            """,
            "externalDocs": {
                "description": "Hybrid Search Tutorial",
                "url": "https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"
            }
        },
        {
            "name": "ask",
            "description": """
## ğŸ’¬ Basic RAG Q&A

Simple Retrieval-Augmented Generation with **Redis caching**.

### Features

- Fast responses for repeated queries (6-hour cache TTL)
- Configurable retrieval (`top_k`)
- Support for BM25-only or hybrid search
- Multiple LLM models (llama3.2:1b, llama3.2:3b, qwen2.5:7b)

### When to Use

- Quick prototyping
- Non-streaming responses needed
- Cache-friendly workloads

**Cache Hit Rate**: ~30% in production (6h TTL).
            """
        },
        {
            "name": "stream",
            "description": """
## âš¡ Streaming RAG Responses

Real-time answer generation with **Server-Sent Events (SSE)**.

### Event Sequence

1. **Metadata Event**: Sources, chunks used, search mode
2. **Chunk Events**: Incremental text fragments
3. **Done Event**: Final complete answer

### Use Cases

- Chat interfaces
- Real-time user feedback
- Mobile apps (Telegram bot)

**Note**: Responses cannot be interactively tested in Scalar UI. Use code examples below.
            """
        },
        {
            "name": "agentic-rag",
            "description": """
## ğŸ¤– Agentic RAG (LangGraph)

Intelligent RAG with **adaptive retrieval** and **decision-making**.

### Workflow

```
Guardrail â†’ Retrieve â†’ Grade â†’ Rewrite/Generate
    â†“                      â†“
Out of Scope?      Not Relevant? â†’ Query Rewriting (up to 2 attempts)
```

### Advantages over Basic RAG

- âœ… Query validation (filters nonsense queries)
- âœ… Document relevance grading (ensures quality)
- âœ… Automatic query rewriting (improves recall)
- âœ… Full reasoning transparency (debugging + trust)
- âœ… Langfuse tracing (observability)

### Trade-offs

- âš ï¸ Higher latency (~3-5s vs ~2-3s)
- âš ï¸ More LLM calls (3-5 vs 1)

**When to Use**: Production workloads where quality > speed.
            """,
            "externalDocs": {
                "description": "Agentic RAG Deep Dive",
                "url": "https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"
            }
        }
    ],

    # Swagger UI é…ç½® (ä¿ç•™ç”¨äºå¯¹æ¯”)
    swagger_ui_parameters={
        "defaultModelsExpandDepth": -1,
        "docExpansion": "list",
        "filter": True,
        "syntaxHighlight.theme": "monokai"
    },

    # ReDoc é…ç½®
    redoc_url="/redoc"
)


# è‡ªå®šä¹‰ OpenAPI Schema (Scalar ä¼˜åŒ–)
def custom_openapi():
    """Generate enhanced OpenAPI schema with Scalar-specific extensions"""
    if app.openapi_schema:
        return app.openapi_schema

    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        description=app.description,
        routes=app.routes,
        tags=app.openapi_tags,
        servers=app.servers,
        contact=app.contact,
        license_info=app.license_info,
    )

    # Scalar ç‰¹å®šæ‰©å±•
    openapi_schema["info"]["x-logo"] = {
        "url": "https://raw.githubusercontent.com/Yemu-Yu/arxiv-paper-curator/main/static/logo.png",
        "altText": "arXiv Paper Curator",
        "href": "https://github.com/Yemu-Yu/arxiv-paper-curator"
    }

    # å®‰å…¨æ–¹æ¡ˆå®šä¹‰ (æœªæ¥å®ç°)
    if "securitySchemes" not in openapi_schema.get("components", {}):
        openapi_schema.setdefault("components", {})["securitySchemes"] = {
            "ApiKeyAuth": {
                "type": "apiKey",
                "in": "header",
                "name": "X-API-Key",
                "description": "API key for authentication (future feature)"
            }
        }

    # Scalar Tag Groups (åˆ†ç»„æ˜¾ç¤º)
    openapi_schema["x-tagGroups"] = [
        {
            "name": "Core Services",
            "tags": ["Health", "hybrid-search"]
        },
        {
            "name": "RAG Endpoints",
            "tags": ["ask", "stream", "agentic-rag"]
        }
    ]

    app.openapi_schema = openapi_schema
    return app.openapi_schema


# åº”ç”¨è‡ªå®šä¹‰ OpenAPI
app.openapi = custom_openapi

# (å…¶ä½™ä»£ç ä¿æŒä¸å˜)
```

### 2.2 å¢å¼º Schema Examples

**æ–‡ä»¶**: `src/schemas/api/search.py` å’Œ `src/schemas/api/ask.py`

**å·²æœ‰ä»£ç å®¡æŸ¥**: å½“å‰ä»£ç **å·²ç»åŒ…å«äº† examples**,ä½†éœ€è¦éªŒè¯æ ¼å¼:

```bash
# æ£€æŸ¥ç°æœ‰ examples
grep -A 10 "json_schema_extra" src/schemas/api/ask.py | head -20
```

**å¦‚æœæ ¼å¼æ­£ç¡®**(ä½¿ç”¨ `ConfigDict` å’Œ `json_schema_extra`),åˆ™æ— éœ€ä¿®æ”¹ã€‚

### 2.3 ä¿®å¤ SSE ç«¯ç‚¹æ–‡æ¡£ (é‡è¦!)

**é—®é¢˜**: `/stream` ç«¯ç‚¹è¿”å› `media_type="text/plain"` è€Œéæ ‡å‡† `text/event-stream`

**æ–‡ä»¶**: `src/routers/ask.py` (ç¬¬ 271-273 è¡Œ)

**ä¿®æ”¹**:

```python
# åŸä»£ç  (ç¬¬ 271-273 è¡Œ)
return StreamingResponse(
    generate_stream(),
    media_type="text/plain",  # âŒ é”™è¯¯
    headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
)

# ä¿®æ”¹ä¸º:
return StreamingResponse(
    generate_stream(),
    media_type="text/event-stream",  # âœ… æ­£ç¡®
    headers={
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "X-Accel-Buffering": "no"  # é˜²æ­¢ Nginx ç¼“å†²
    }
)
```

**åŒæ—¶æ·»åŠ  OpenAPI æ–‡æ¡£**:

```python
# åœ¨ @stream_router.post("/stream") è£…é¥°å™¨ä¸­æ·»åŠ  responses å‚æ•°

@stream_router.post(
    "/stream",
    responses={
        200: {
            "description": "Server-Sent Events stream with JSON payloads",
            "content": {
                "text/event-stream": {
                    "schema": {
                        "type": "string",
                        "format": "binary",
                        "description": "SSE stream with newline-delimited JSON events"
                    },
                    "examples": {
                        "successful_stream": {
                            "summary": "Complete SSE Flow (3 steps)",
                            "value": """data: {"sources": ["https://arxiv.org/pdf/1706.03762.pdf"], "chunks_used": 3, "search_mode": "hybrid"}

data: {"chunk": "Based on "}

data: {"chunk": "the research "}

data: {"chunk": "papers, transformers..."}

data: {"answer": "Based on the research papers, transformers are neural network architectures...", "done": true}
"""
                        },
                        "cached_stream": {
                            "summary": "Cached Response (simulated streaming)",
                            "value": """data: {"sources": ["..."], "chunks_used": 3, "search_mode": "hybrid"}

data: {"chunk": "Cached "}

data: {"chunk": "response..."}

data: {"answer": "Cached response from Redis", "done": true}
"""
                        }
                    }
                }
            }
        },
        500: {
            "description": "Server error during streaming",
            "content": {
                "text/event-stream": {
                    "example": 'data: {"error": "Internal server error"}\n\n'
                }
            }
        }
    },
    summary="Stream RAG answer in real-time (SSE)",
    description="""
## âš¡ Real-time Streaming RAG

Get RAG answers with **Server-Sent Events (SSE)** for progressive display.

### Event Sequence

1. **Metadata Event** (first):
   ```json
   {"sources": [...], "chunks_used": 3, "search_mode": "hybrid"}
   ```

2. **Chunk Events** (multiple):
   ```json
   {"chunk": "text fragment "}
   ```

3. **Done Event** (last):
   ```json
   {"answer": "complete answer text", "done": true}
   ```

4. **Error Event** (if failed):
   ```json
   {"error": "error message"}
   ```

### Client Examples

#### JavaScript (EventSource)

**âš ï¸ Note**: `EventSource` API only supports GET requests. For POST, use `fetch` with streaming.

```javascript
// Using fetch for POST + SSE
const response = await fetch('/api/v1/stream', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
        query: "What are transformers?",
        top_k: 3
    })
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
    const {done, value} = await reader.read();
    if (done) break;

    const text = decoder.decode(value);
    const lines = text.split('\\n');

    for (const line of lines) {
        if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6));

            if (data.chunk) {
                process.stdout.write(data.chunk);  // Progressive display
            }
            if (data.done) {
                console.log('\\nComplete!');
            }
        }
    }
}
```

#### Python (httpx)

```python
import httpx
import json

async with httpx.AsyncClient() as client:
    async with client.stream(
        "POST",
        "http://localhost:8000/api/v1/stream",
        json={"query": "What are transformers?", "top_k": 3},
        timeout=30.0
    ) as response:
        async for line in response.aiter_lines():
            if line.startswith("data: "):
                data = json.loads(line[6:])

                if "chunk" in data:
                    print(data["chunk"], end="", flush=True)
                if data.get("done"):
                    print(f"\\n\\nFinal answer: {data['answer']}")
```

#### cURL (for testing)

```bash
curl -N -X POST http://localhost:8000/api/v1/stream \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "What is attention mechanism?",
    "top_k": 3
  }'
```

### Cache Behavior

- âœ… **Cache Hit**: Streams cached response (simulated chunk-by-chunk)
- âŒ **Cache Miss**: Real-time LLM generation

### Performance

- First byte latency: < 500ms
- Chunk frequency: 10-50 chunks/second
- Total time: 2-8 seconds (depends on answer length)

### âš ï¸ Important Notes

1. **Not Interactive in Scalar UI**: SSE endpoints cannot be tested directly in the browser UI. Use code examples above.
2. **Buffering Issues**: If using Nginx, ensure `proxy_buffering off` is set.
3. **Timeout**: Default client timeout may be too short. Use 30s+.
    """,
    operation_id="stream_rag_answer",
    tags=["stream"]
)
async def ask_question_stream(...):
    # å®ç°ä¿æŒä¸å˜
    ...
```

### 2.4 éªŒè¯ OpenAPI è§„èŒƒ

**è„šæœ¬**: `scripts/validate_openapi.sh`

```bash
#!/bin/bash
# scripts/validate_openapi.sh
set -e

echo "ğŸ” Validating Enhanced OpenAPI Specification..."

# 1. ç¡®ä¿ API è¿è¡Œ
if ! curl -s http://localhost:8000/api/v1/health > /dev/null 2>&1; then
    echo "âŒ API not running. Start with: docker compose up -d api"
    exit 1
fi

# 2. ä¸‹è½½æ–°çš„ OpenAPI spec
echo "ğŸ“¥ Downloading updated OpenAPI spec..."
curl -s http://localhost:8000/openapi.json > openapi_v2_enhanced.json

# 3. åŸºæœ¬ç»“æ„æ£€æŸ¥
echo "âœ… Basic structure check..."

# æ£€æŸ¥ç‰ˆæœ¬
VERSION=$(jq -r '.openapi' openapi_v2_enhanced.json)
if [[ "$VERSION" != "3.1.0" && "$VERSION" != "3.0.2" ]]; then
    echo "âŒ Invalid OpenAPI version: $VERSION"
    exit 1
fi

# æ£€æŸ¥ç«¯ç‚¹æ•°é‡
PATHS_COUNT=$(jq '.paths | length' openapi_v2_enhanced.json)
if [ "$PATHS_COUNT" -ne 6 ]; then
    echo "âŒ Expected 6 endpoints, found $PATHS_COUNT"
    exit 1
fi

# æ£€æŸ¥è”ç³»ä¿¡æ¯
CONTACT_EMAIL=$(jq -r '.info.contact.email' openapi_v2_enhanced.json)
if [ "$CONTACT_EMAIL" == "null" ]; then
    echo "âš ï¸  Warning: Missing contact email"
fi

# æ£€æŸ¥æœåŠ¡å™¨é…ç½®
SERVERS_COUNT=$(jq '.servers | length' openapi_v2_enhanced.json)
if [ "$SERVERS_COUNT" -lt 1 ]; then
    echo "âŒ Missing server configuration"
    exit 1
fi

echo "âœ… Basic validation passed"

# 4. Spectral Linting (OpenAPI æœ€ä½³å®è·µ)
echo "ğŸ”¬ Running Spectral linting..."
npx @stoplight/spectral-cli lint openapi_v2_enhanced.json \
  --ruleset https://raw.githubusercontent.com/stoplightio/spectral/master/rulesets/oas/index.json \
  || echo "âš ï¸  Linting found issues (review above)"

# 5. è¯¦ç»†æ£€æŸ¥
echo ""
echo "ğŸ“Š Detailed Analysis:"
echo "  OpenAPI Version:    $(jq -r '.openapi' openapi_v2_enhanced.json)"
echo "  API Title:          $(jq -r '.info.title' openapi_v2_enhanced.json)"
echo "  API Version:        $(jq -r '.info.version' openapi_v2_enhanced.json)"
echo "  Total Endpoints:    $(jq '.paths | length' openapi_v2_enhanced.json)"
echo "  Total Schemas:      $(jq '.components.schemas | length' openapi_v2_enhanced.json)"
echo "  Total Tags:         $(jq '.tags | length' openapi_v2_enhanced.json)"
echo "  Security Schemes:   $(jq '.components.securitySchemes | length' openapi_v2_enhanced.json)"

# 6. æ£€æŸ¥æ‰€æœ‰ POST ç«¯ç‚¹æ˜¯å¦æœ‰ examples
echo ""
echo "ğŸ” Checking request examples..."

MISSING_EXAMPLES=0
for path in $(jq -r '.paths | keys[]' openapi_v2_enhanced.json); do
    for method in $(jq -r ".paths[\"$path\"] | keys[]" openapi_v2_enhanced.json); do
        if [ "$method" == "post" ]; then
            HAS_EXAMPLE=$(jq -r ".paths[\"$path\"].post.requestBody.content.\"application/json\" | has(\"examples\") or has(\"example\") or .schema | has(\"examples\")" openapi_v2_enhanced.json)

            if [ "$HAS_EXAMPLE" != "true" ]; then
                echo "  âš ï¸  Missing example: $method $path"
                ((MISSING_EXAMPLES++))
            fi
        fi
    done
done

if [ $MISSING_EXAMPLES -eq 0 ]; then
    echo "  âœ… All POST endpoints have examples"
else
    echo "  âš ï¸  $MISSING_EXAMPLES endpoints missing examples"
fi

# 7. ä¿å­˜éªŒè¯é€šè¿‡çš„ spec
cp openapi_v2_enhanced.json openapi_validated.json
echo ""
echo "âœ… Validation complete!"
echo "ğŸ“ Saved validated spec to: openapi_validated.json"
```

**è¿è¡ŒéªŒè¯**:

```bash
chmod +x scripts/validate_openapi.sh
./scripts/validate_openapi.sh
```

### Day 2 éªŒæ”¶æ ‡å‡†

- [x] `openapi_v2_enhanced.json` å¯¼å‡ºæˆåŠŸ
- [x] Spectral linting é€šè¿‡ (æˆ–åªæœ‰ info çº§åˆ«è­¦å‘Š)
- [x] æ‰€æœ‰ 6 ä¸ªç«¯ç‚¹å­˜åœ¨
- [x] æ‰€æœ‰ POST ç«¯ç‚¹æœ‰ examples
- [x] `/stream` ç«¯ç‚¹ `media_type` ä¿®æ”¹ä¸º `text/event-stream`
- [x] è”ç³»ä¿¡æ¯å’ŒæœåŠ¡å™¨é…ç½®å®Œæ•´

---

## ğŸ”§ Day 3: Scalar é™æ€ç«™ç‚¹ç”Ÿæˆ

### 3.1 ç”Ÿæˆ Scalar é™æ€ HTML

**æ–¹æ³•**: ä½¿ç”¨ `@scalar/api-reference` çš„ CDN ç‰ˆæœ¬

**æ–‡ä»¶**: `static/api-docs.html`

```html
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>arXiv Paper Curator API Documentation</title>
    <meta name="description" content="Interactive API documentation for arXiv Paper Curator RAG system">

    <!-- Scalar CSS -->
    <style>
        body {
            margin: 0;
            padding: 0;
        }
    </style>
</head>
<body>
    <!-- Scalar API Reference -->
    <script
        id="api-reference"
        type="application/json"
        data-url="http://localhost:8000/openapi.json">
    </script>

    <script src="https://cdn.jsdelivr.net/npm/@scalar/api-reference@1.25.30/dist/browser/standalone.min.js"></script>

    <script>
        // Scalar configuration
        const configuration = {
            spec: {
                url: 'http://localhost:8000/openapi.json',
            },
            theme: 'purple',  // purple, blue, green, default, moon, solarized
            layout: 'modern',  // modern, classic
            darkMode: false,
            showSidebar: true,
            hideDarkModeToggle: false,
            hideDownloadButton: false,
            hideTestRequestSnippets: false,
            defaultHttpClient: {
                targetKey: 'javascript',
                clientKey: 'fetch'
            },
            servers: [
                {
                    url: 'http://localhost:8000',
                    description: 'ğŸ› ï¸ Development (Local)'
                },
                {
                    url: 'http://api:8000',
                    description: 'ğŸ³ Docker Internal'
                }
            ],
            authentication: {
                // Future: Enable when API keys are implemented
                // apiKey: {
                //     token: 'YOUR_API_KEY'
                // }
            },
            tagsSorter: 'alpha',  // alpha or custom function
            operationsSorter: 'alpha',  // alpha, method, or custom function
            customCss: `
                /* Custom styling */
                .scalar-api-reference {
                    --scalar-color-1: #8b5cf6;
                    --scalar-color-2: #a78bfa;
                    --scalar-color-3: #c4b5fd;
                }

                /* Improve readability */
                .scalar-api-reference pre {
                    font-size: 13px;
                    line-height: 1.6;
                }

                /* Highlight SSE warning */
                [data-operation-id="stream_rag_answer"] .description {
                    background-color: #fef3c7;
                    padding: 1rem;
                    border-left: 4px solid #f59e0b;
                    margin: 1rem 0;
                }
            `
        };

        // Initialize Scalar
        const apiReference = document.getElementById('api-reference');

        // Render API documentation
        window.addEventListener('DOMContentLoaded', () => {
            // Scalar will automatically initialize
            console.log('Scalar API Reference loaded');
        });
    </script>
</body>
</html>
```

### 3.2 é…ç½® FastAPI é™æ€æ–‡ä»¶æœåŠ¡

**æ–‡ä»¶**: `src/main.py` (æ·»åŠ é™æ€æ–‡ä»¶æŒ‚è½½)

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from fastapi.staticfiles import StaticFiles
import os

# åœ¨ app åˆå§‹åŒ–åæ·»åŠ  (ç¬¬ 120 è¡Œé™„è¿‘,include_router ä¹‹å‰)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½• (ç”¨äº Scalar HTML)
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")
    logger.info("Static files mounted at /static")

# æ·»åŠ  Scalar æ–‡æ¡£é‡å®šå‘
from fastapi.responses import RedirectResponse

@app.get("/scalar", include_in_schema=False)
async def redirect_to_scalar():
    """Redirect /scalar to static Scalar documentation"""
    return RedirectResponse(url="/static/api-docs.html")

# Include routers (åŸæœ‰ä»£ç )
app.include_router(ping.router, prefix="/api/v1")
# ...
```

### 3.3 åˆ›å»º static ç›®å½•å¹¶éªŒè¯

```bash
# 1. åˆ›å»ºç›®å½•
mkdir -p static

# 2. åˆ›å»º HTML æ–‡ä»¶
cat > static/api-docs.html <<'EOF'
[ç²˜è´´ä¸Šé¢ 3.1 ä¸­çš„å®Œæ•´ HTML å†…å®¹]
EOF

# 3. é‡å¯ API
docker compose restart api

# 4. ç­‰å¾…å¯åŠ¨
sleep 10

# 5. æµ‹è¯•è®¿é—®
open http://localhost:8000/scalar
# æˆ–
curl -I http://localhost:8000/scalar
# æœŸæœ›: HTTP/1.1 307 Temporary Redirect -> /static/api-docs.html
```

### 3.4 Nginx é…ç½® (ç”Ÿäº§ç¯å¢ƒå¯é€‰)

**æ–‡ä»¶**: `nginx/scalar.conf`

```nginx
server {
    listen 80;
    server_name docs.arxiv-curator.local;

    # Scalar é™æ€æ–‡æ¡£
    location / {
        root /usr/share/nginx/html;
        try_files /api-docs.html =404;
    }

    # API ä»£ç† (ç”¨äº Scalar çš„"Try it out"åŠŸèƒ½)
    location /api/ {
        proxy_pass http://api:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # CORS headers (å…è®¸ Scalar è·¨åŸŸè°ƒç”¨)
        add_header Access-Control-Allow-Origin *;
        add_header Access-Control-Allow-Methods "GET, POST, OPTIONS";
        add_header Access-Control-Allow-Headers "Content-Type, Authorization";

        # Handle preflight
        if ($request_method = OPTIONS) {
            return 204;
        }
    }

    # OpenAPI spec ä»£ç†
    location /openapi.json {
        proxy_pass http://api:8000/openapi.json;
        proxy_set_header Host $host;

        add_header Access-Control-Allow-Origin *;
    }

    # SSE ç‰¹æ®Šå¤„ç†
    location /api/v1/stream {
        proxy_pass http://api:8000;
        proxy_set_header Host $host;

        # å…³é”®: ç¦ç”¨ç¼“å†²
        proxy_buffering off;
        proxy_cache off;

        # SSE ä¸“ç”¨
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        chunked_transfer_encoding off;

        # è¶…æ—¶
        proxy_read_timeout 300s;
        proxy_send_timeout 300s;
    }
}
```

**æ·»åŠ åˆ° `compose.yml` (å¯é€‰)**:

```yaml
  nginx:
    image: nginx:alpine
    container_name: arxiv-nginx
    ports:
      - "7998:80"
    volumes:
      - ./static:/usr/share/nginx/html:ro
      - ./nginx/scalar.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - api
    networks:
      - rag-network
```

### Day 3 éªŒæ”¶æ ‡å‡†

- [x] `static/api-docs.html` æ–‡ä»¶å­˜åœ¨
- [x] è®¿é—® `http://localhost:8000/scalar` è¿”å› Scalar UI
- [x] Scalar UI åŠ è½½ OpenAPI spec æˆåŠŸ
- [x] æ‰€æœ‰ 6 ä¸ªç«¯ç‚¹åœ¨ Scalar ä¾§è¾¹æ å¯è§
- [x] "Try it out" åŠŸèƒ½å¯ä»¥è°ƒç”¨ `/api/v1/health`
- [x] (å¯é€‰) Nginx å®¹å™¨è¿è¡Œåœ¨ 7998 ç«¯å£

---

## ğŸ”§ Day 4: SSE ç«¯ç‚¹ä¼˜åŒ–å’Œæµ‹è¯•

### 4.1 SSE ç«¯ç‚¹é›†æˆæµ‹è¯•

**è„šæœ¬**: `tests/test_sse_streaming.py`

```python
#!/usr/bin/env python3
"""
Integration tests for SSE streaming endpoint
æµ‹è¯• /stream ç«¯ç‚¹çš„å®Œæ•´åŠŸèƒ½
"""

import asyncio
import json
import httpx
import pytest

BASE_URL = "http://localhost:8000"

@pytest.mark.asyncio
async def test_sse_basic_flow():
    """Test basic SSE streaming flow"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        async with client.stream(
            "POST",
            f"{BASE_URL}/api/v1/stream",
            json={
                "query": "What is attention mechanism?",
                "top_k": 3,
                "use_hybrid": False,
                "model": "llama3.2:1b"
            }
        ) as response:
            assert response.status_code == 200
            assert response.headers["content-type"] == "text/event-stream; charset=utf-8"

            events = []
            metadata_received = False
            chunks_received = 0
            done_received = False
            full_answer = ""

            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data = json.loads(line[6:])
                    events.append(data)

                    # 1. First event should be metadata
                    if not metadata_received and "sources" in data:
                        assert "chunks_used" in data
                        assert "search_mode" in data
                        metadata_received = True
                        print(f"âœ… Metadata: {data['chunks_used']} chunks, mode={data['search_mode']}")

                    # 2. Chunk events
                    if "chunk" in data:
                        chunks_received += 1
                        full_answer += data["chunk"]
                        print(f"ğŸ“¦ Chunk {chunks_received}: {data['chunk'][:20]}...")

                    # 3. Done event
                    if data.get("done"):
                        assert "answer" in data
                        done_received = True
                        print(f"âœ… Done event received. Final answer length: {len(data['answer'])}")
                        break

            # Assertions
            assert metadata_received, "Missing metadata event"
            assert chunks_received > 0, "No text chunks received"
            assert done_received, "Missing done event"
            assert len(full_answer) > 50, "Answer too short"

            print(f"\nâœ… SSE Flow Complete:")
            print(f"  - Total events: {len(events)}")
            print(f"  - Text chunks: {chunks_received}")
            print(f"  - Final answer length: {len(full_answer)}")


@pytest.mark.asyncio
async def test_sse_cached_response():
    """Test SSE with cached response"""
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ (å¡«å……ç¼“å­˜)
    query = f"Test query for cache {asyncio.get_event_loop().time()}"

    request_data = {
        "query": query,
        "top_k": 1,
        "use_hybrid": False,
        "model": "llama3.2:1b"
    }

    async with httpx.AsyncClient(timeout=30.0) as client:
        # First call
        async with client.stream("POST", f"{BASE_URL}/api/v1/stream", json=request_data) as response1:
            events1 = []
            async for line in response1.aiter_lines():
                if line.startswith("data: "):
                    events1.append(json.loads(line[6:]))
                    if json.loads(line[6:]).get("done"):
                        break

        # Second call (should hit cache)
        await asyncio.sleep(1)  # ç¡®ä¿ç¼“å­˜å·²å†™å…¥

        async with client.stream("POST", f"{BASE_URL}/api/v1/stream", json=request_data) as response2:
            events2 = []
            async for line in response2.aiter_lines():
                if line.startswith("data: "):
                    events2.append(json.loads(line[6:]))
                    if json.loads(line[6:]).get("done"):
                        break

        # æ¯”è¾ƒç»“æœ (ç¼“å­˜å‘½ä¸­åº”è¯¥è¿”å›ç›¸åŒå†…å®¹)
        answer1 = next(e["answer"] for e in events1 if "done" in e)
        answer2 = next(e["answer"] for e in events2 if "done" in e)

        assert answer1 == answer2, "Cached response mismatch"
        print(f"âœ… Cache hit verified: answers match")


@pytest.mark.asyncio
async def test_sse_error_handling():
    """Test SSE error handling"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        # Invalid request (empty query)
        try:
            async with client.stream(
                "POST",
                f"{BASE_URL}/api/v1/stream",
                json={"query": "", "top_k": 3}
            ) as response:
                assert response.status_code == 422, "Should return validation error"
                print("âœ… Validation error handled correctly")
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 422:
                print("âœ… Validation error raised correctly")


if __name__ == "__main__":
    print("ğŸ§ª Running SSE Integration Tests...")
    pytest.main([__file__, "-v", "-s"])
```

**è¿è¡Œæµ‹è¯•**:

```bash
# å®‰è£… pytest (å¦‚æœæœªå®‰è£…)
pip install pytest pytest-asyncio

# è¿è¡Œæµ‹è¯•
pytest tests/test_sse_streaming.py -v -s
```

### 4.2 æ€§èƒ½å¯¹æ¯” (SSE vs éæµå¼)

**è„šæœ¬**: `scripts/compare_streaming_performance.py`

```python
#!/usr/bin/env python3
"""Compare streaming vs non-streaming performance"""

import asyncio
import time
import httpx
import json

BASE_URL = "http://localhost:8000"

async def test_non_streaming():
    """Test regular /ask endpoint"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        start = time.time()

        response = await client.post(
            f"{BASE_URL}/api/v1/ask",
            json={
                "query": "What is transformer architecture?",
                "top_k": 3,
                "use_hybrid": False,
                "model": "llama3.2:1b"
            }
        )

        latency = time.time() - start
        data = response.json()

        return {
            "mode": "non-streaming",
            "total_latency": latency,
            "answer_length": len(data["answer"]),
            "chunks_used": data["chunks_used"]
        }

async def test_streaming():
    """Test /stream endpoint"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        start = time.time()
        first_chunk_time = None
        chunks_received = 0

        async with client.stream(
            "POST",
            f"{BASE_URL}/api/v1/stream",
            json={
                "query": "What is transformer architecture?",
                "top_k": 3,
                "use_hybrid": False,
                "model": "llama3.2:1b"
            }
        ) as response:
            full_answer = ""

            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data = json.loads(line[6:])

                    if "chunk" in data and first_chunk_time is None:
                        first_chunk_time = time.time() - start

                    if "chunk" in data:
                        chunks_received += 1
                        full_answer += data["chunk"]

                    if data.get("done"):
                        break

        total_latency = time.time() - start

        return {
            "mode": "streaming",
            "total_latency": total_latency,
            "first_chunk_latency": first_chunk_time,
            "chunks_received": chunks_received,
            "answer_length": len(full_answer)
        }

async def main():
    print("âš¡ Comparing Streaming vs Non-Streaming Performance\n")
    print("="*60)

    # Run tests
    non_stream_result = await test_non_streaming()
    await asyncio.sleep(2)  # é¿å…ç¼“å­˜å½±å“

    stream_result = await test_streaming()

    # Display results
    print("\nğŸ“Š Results:\n")

    print(f"Non-Streaming (/ask):")
    print(f"  Total Latency:    {non_stream_result['total_latency']:.2f}s")
    print(f"  Answer Length:    {non_stream_result['answer_length']} chars")
    print(f"  Chunks Used:      {non_stream_result['chunks_used']}")

    print(f"\nStreaming (/stream):")
    print(f"  Total Latency:    {stream_result['total_latency']:.2f}s")
    print(f"  First Chunk:      {stream_result['first_chunk_latency']:.2f}s âš¡")
    print(f"  Chunks Received:  {stream_result['chunks_received']}")
    print(f"  Answer Length:    {stream_result['answer_length']} chars")

    # Calculate metrics
    ttfb_improvement = (1 - stream_result['first_chunk_latency'] / non_stream_result['total_latency']) * 100

    print(f"\nğŸ’¡ Insights:")
    print(f"  Time-to-First-Byte improvement: {ttfb_improvement:.1f}% faster")
    print(f"  Total latency difference:       {abs(stream_result['total_latency'] - non_stream_result['total_latency']):.2f}s")

    if stream_result['first_chunk_latency'] < non_stream_result['total_latency'] / 2:
        print(f"  âœ… Streaming provides better perceived performance")
    else:
        print(f"  âš ï¸  Streaming overhead detected")

if __name__ == "__main__":
    asyncio.run(main())
```

### Day 4 éªŒæ”¶æ ‡å‡†

- [x] `test_sse_streaming.py` æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [x] SSE ç«¯ç‚¹è¿”å›æ­£ç¡®çš„ `Content-Type: text/event-stream`
- [x] å…ƒæ•°æ®äº‹ä»¶ã€chunk äº‹ä»¶ã€done äº‹ä»¶é¡ºåºæ­£ç¡®
- [x] ç¼“å­˜åŠŸèƒ½åœ¨æµå¼æ¨¡å¼ä¸‹æ­£å¸¸å·¥ä½œ
- [x] æµå¼ TTFB æ¯”éæµå¼å¿« 30%+

---

## ğŸ”§ Day 5: å®‰å…¨å®¡è®¡å’Œè„±æ•

### 5.1 OpenAPI Spec å®‰å…¨æ‰«æ

**è„šæœ¬**: `scripts/security_audit.sh`

```bash
#!/bin/bash
# scripts/security_audit.sh
# æ‰«æ OpenAPI spec ä¸­çš„æ•æ„Ÿä¿¡æ¯

set -e

echo "ğŸ”’ Security Audit for OpenAPI Specification"
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="

SPEC_FILE="openapi_v2_enhanced.json"

if [ ! -f "$SPEC_FILE" ]; then
    echo "âŒ $SPEC_FILE not found. Run validation first."
    exit 1
fi

# 1. æ£€æŸ¥å†…éƒ¨ IP åœ°å€
echo ""
echo "1. Checking for internal IP addresses..."
INTERNAL_IPS=$(grep -E '192\.168\.|10\.|172\.(1[6-9]|2[0-9]|3[01])\.' "$SPEC_FILE" || true)
if [ -n "$INTERNAL_IPS" ]; then
    echo "âš ï¸  Found internal IPs:"
    echo "$INTERNAL_IPS"
else
    echo "âœ… No internal IPs found"
fi

# 2. æ£€æŸ¥æ•æ„Ÿç«¯å£
echo ""
echo "2. Checking for non-standard ports..."
SENSITIVE_PORTS=$(grep -E ':(5432|6379|9200|3001|11434|8080)' "$SPEC_FILE" || true)
if [ -n "$SENSITIVE_PORTS" ]; then
    echo "âš ï¸  Found internal service ports:"
    echo "$SENSITIVE_PORTS" | grep -o ':[0-9]\+' | sort | uniq
else
    echo "âœ… No internal ports exposed"
fi

# 3. æ£€æŸ¥å¯†é’¥/å¯†ç æ¨¡å¼
echo ""
echo "3. Checking for potential secrets..."
SECRETS=$(grep -iE '(password|secret|apikey|api_key|token|bearer).*:.*"[^"]{10,}"' "$SPEC_FILE" || true)
if [ -n "$SECRETS" ]; then
    echo "âš ï¸  Potential secrets found:"
    echo "$SECRETS"
else
    echo "âœ… No hardcoded secrets detected"
fi

# 4. æ£€æŸ¥ç¯å¢ƒå˜é‡æ³„éœ²
echo ""
echo "4. Checking for environment variable leaks..."
ENV_VARS=$(grep -E '\$\{[A-Z_]+\}|process\.env\.' "$SPEC_FILE" || true)
if [ -n "$ENV_VARS" ]; then
    echo "âš ï¸  Environment variable references:"
    echo "$ENV_VARS"
else
    echo "âœ… No environment variables exposed"
fi

# 5. æ£€æŸ¥å†…éƒ¨æœåŠ¡åç§°
echo ""
echo "5. Checking for internal service names..."
INTERNAL_SERVICES=$(grep -iE '(postgres|opensearch|redis|ollama|langfuse|clickhouse|minio)' "$SPEC_FILE" || true)
if [ -n "$INTERNAL_SERVICES" ]; then
    echo "âš ï¸  Internal service references found (review if acceptable):"
    echo "$INTERNAL_SERVICES" | grep -oiE '(postgres|opensearch|redis|ollama|langfuse|clickhouse|minio)' | sort | uniq -c
else
    echo "âœ… No internal service names found"
fi

# 6. æ£€æŸ¥è°ƒè¯•ä¿¡æ¯
echo ""
echo "6. Checking for debug information..."
DEBUG_INFO=$(grep -iE '(debug|trace|stacktrace|internal error|TODO|FIXME)' "$SPEC_FILE" || true)
if [ -n "$DEBUG_INFO" ]; then
    echo "âš ï¸  Debug information found:"
    echo "$DEBUG_INFO" | head -5
else
    echo "âœ… No debug information exposed"
fi

# 7. æ£€æŸ¥ email å’Œè”ç³»ä¿¡æ¯
echo ""
echo "7. Checking contact information..."
EMAIL=$(jq -r '.info.contact.email' "$SPEC_FILE")
if [ "$EMAIL" == "null" ] || [ "$EMAIL" == "support@example.com" ]; then
    echo "âš ï¸  Placeholder or missing email: $EMAIL"
else
    echo "âœ… Contact email set: $EMAIL"
fi

# 8. ç”ŸæˆæŠ¥å‘Š
echo ""
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="
echo "ğŸ“‹ Security Audit Summary"
echo "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "=" "="

# è®¡ç®—é£é™©åˆ†æ•°
RISK_SCORE=0

if [ -n "$INTERNAL_IPS" ]; then ((RISK_SCORE+=20)); fi
if [ -n "$SENSITIVE_PORTS" ]; then ((RISK_SCORE+=15)); fi
if [ -n "$SECRETS" ]; then ((RISK_SCORE+=30)); fi
if [ -n "$ENV_VARS" ]; then ((RISK_SCORE+=10)); fi
if [ -n "$INTERNAL_SERVICES" ]; then ((RISK_SCORE+=5)); fi
if [ -n "$DEBUG_INFO" ]; then ((RISK_SCORE+=10)); fi

echo "Risk Score: $RISK_SCORE / 100"

if [ $RISK_SCORE -eq 0 ]; then
    echo "âœ… Security Grade: A (Excellent)"
elif [ $RISK_SCORE -le 20 ]; then
    echo "ğŸŸ¢ Security Grade: B (Good)"
elif [ $RISK_SCORE -le 40 ]; then
    echo "ğŸŸ¡ Security Grade: C (Acceptable with review)"
else
    echo "ğŸ”´ Security Grade: D (Requires remediation)"
fi

echo ""
echo "ğŸ’¡ Recommendations:"
echo "  1. Review all warnings above"
echo "  2. Replace placeholder emails with real contacts"
echo "  3. Remove internal service names from examples if unnecessary"
echo "  4. Use environment-specific server URLs (no hardcoded ports)"
echo "  5. Re-run audit after making changes"
```

**è¿è¡Œå®¡è®¡**:

```bash
chmod +x scripts/security_audit.sh
./scripts/security_audit.sh
```

### 5.2 è„±æ•ä¿®å¤

**å¦‚æœå®¡è®¡å‘ç°é—®é¢˜,åº”ç”¨ä»¥ä¸‹ä¿®å¤**:

```python
# src/main.py - ä¿®å¤æœåŠ¡å™¨ URL

# âŒ é”™è¯¯ (æš´éœ²å†…éƒ¨ç«¯å£)
servers=[
    {
        "url": "http://localhost:8000",
        "description": "Development"
    },
    {
        "url": "http://api:8000",  # â† å†…éƒ¨æœåŠ¡å
        "description": "Docker Internal"
    }
]

# âœ… æ­£ç¡® (ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–ä»…å…¬å¼€ URL)
servers=[
    {
        "url": os.getenv("PUBLIC_API_URL", "http://localhost:8000"),
        "description": "ğŸ› ï¸ Development Server"
    }
]
```

```python
# src/schemas/api/ask.py - è„±æ•ç¤ºä¾‹æ•°æ®

# âŒ é”™è¯¯ (æ³„éœ²å†…éƒ¨ä¿¡æ¯)
class AskResponse(BaseModel):
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "query": "test",
                "answer": "Internal DB ID: 12345, Cache Key: redis://localhost:6379/0/query:..."  # â† æ³„éœ²
            }
        }
    )

# âœ… æ­£ç¡® (ä»…å…¬å¼€ä¿¡æ¯)
class AskResponse(BaseModel):
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "query": "What is attention mechanism?",
                "answer": "Based on the research papers, attention mechanism allows..."  # â† å®‰å…¨
            }
        }
    )
```

### Day 5 éªŒæ”¶æ ‡å‡†

- [x] å®‰å…¨å®¡è®¡è„šæœ¬è¿è¡ŒæˆåŠŸ
- [x] é£é™©åˆ†æ•° â‰¤ 20 (Grade B æˆ–æ›´é«˜)
- [x] æ— ç¡¬ç¼–ç å¯†é’¥æˆ–å¯†ç 
- [x] æ— å†…éƒ¨ IP åœ°å€æš´éœ²
- [x] ç¤ºä¾‹æ•°æ®å·²è„±æ•

---

## ğŸ”§ Day 6: å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œ

### 6.1 ç«¯åˆ°ç«¯éªŒæ”¶æµ‹è¯•

**è„šæœ¬**: `scripts/acceptance_test_v2.sh`

```bash
#!/bin/bash
# scripts/acceptance_test_v2.sh
# å®Œæ•´éªŒæ”¶æµ‹è¯• (ä¿®è®¢ç‰ˆ)

set -e

echo "ğŸ¯ Running Comprehensive Acceptance Tests"
echo "=========================================="

PASS=0
FAIL=0

function test_case() {
    local name="$1"
    local command="$2"

    echo ""
    echo "Testing: $name"

    if eval "$command" > /dev/null 2>&1; then
        echo "âœ… PASS"
        ((PASS++))
    else
        echo "âŒ FAIL"
        ((FAIL++))
        # Show error for debugging
        eval "$command" 2>&1 | head -5
    fi
}

# ========== API Functionality ==========
echo ""
echo "ğŸ“¡ API Functionality Tests"
echo "=========================================="

test_case "API is running" \
    "curl -f -s http://localhost:8000/api/v1/health"

test_case "Health check returns valid JSON" \
    "curl -s http://localhost:8000/api/v1/health | jq .status"

test_case "OpenAPI spec is accessible" \
    "curl -f -s http://localhost:8000/openapi.json > /dev/null"

test_case "Hybrid search works" \
    "curl -f -s -X POST http://localhost:8000/api/v1/hybrid-search/ \
    -H 'Content-Type: application/json' \
    -d '{\"query\":\"test\",\"size\":1}' | jq .total"

test_case "Basic RAG works" \
    "curl -f -s -X POST http://localhost:8000/api/v1/ask \
    -H 'Content-Type: application/json' \
    -d '{\"query\":\"test\",\"top_k\":1,\"use_hybrid\":false}' | jq .answer"

# ========== OpenAPI Specification ==========
echo ""
echo "ğŸ“‹ OpenAPI Specification Tests"
echo "=========================================="

test_case "OpenAPI version is 3.x" \
    "curl -s http://localhost:8000/openapi.json | jq -e '.openapi | startswith(\"3.\")'"

test_case "All 6 endpoints documented" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.paths | length') -eq 6 ]]"

test_case "Contact info is present" \
    "curl -s http://localhost:8000/openapi.json | jq -e '.info.contact.email'"

test_case "Server URLs configured" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.servers | length') -ge 1 ]]"

test_case "Tags are defined" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '.tags | length') -ge 5 ]]"

test_case "Security schemes defined" \
    "curl -s http://localhost:8000/openapi.json | jq -e '.components.securitySchemes'"

test_case "All POST endpoints have examples" \
    "[[ \$(curl -s http://localhost:8000/openapi.json | jq '[.paths[][] | select(.requestBody) | select(.requestBody.content.\"application/json\".examples == null and .requestBody.content.\"application/json\".schema.examples == null)] | length') -eq 0 ]]"

test_case "/stream endpoint has SSE media type" \
    "curl -s http://localhost:8000/openapi.json | jq -e '.paths[\"/api/v1/stream\"].post.responses.\"200\".content.\"text/event-stream\"'"

# ========== Scalar UI ==========
echo ""
echo "ğŸ¨ Scalar UI Tests"
echo "=========================================="

test_case "Scalar HTML is accessible" \
    "curl -f -s http://localhost:8000/static/api-docs.html > /dev/null"

test_case "Scalar redirect works" \
    "curl -s -o /dev/null -w '%{http_code}' http://localhost:8000/scalar | grep -q 307"

test_case "Scalar HTML loads OpenAPI spec" \
    "grep -q 'openapi.json' static/api-docs.html"

# ========== SSE Streaming ==========
echo ""
echo "âš¡ SSE Streaming Tests"
echo "=========================================="

test_case "SSE endpoint returns text/event-stream" \
    "curl -s -N -X POST http://localhost:8000/api/v1/stream \
    -H 'Content-Type: application/json' \
    -d '{\"query\":\"test\",\"top_k\":1}' \
    -w '%{content_type}' -o /dev/null | grep -q 'text/event-stream'"

test_case "SSE stream contains data events" \
    "curl -s -N -X POST http://localhost:8000/api/v1/stream \
    -H 'Content-Type: application/json' \
    -d '{\"query\":\"test\",\"top_k\":1}' | \
    head -10 | grep -q 'data:'"

# ========== Performance ==========
echo ""
echo "âš¡ Performance Tests"
echo "=========================================="

test_case "Health check latency < 1s" \
    "timeout 1 curl -s http://localhost:8000/api/v1/health > /dev/null"

test_case "OpenAPI spec latency < 2s" \
    "timeout 2 curl -s http://localhost:8000/openapi.json > /dev/null"

# ========== Security ==========
echo ""
echo "ğŸ”’ Security Tests"
echo "=========================================="

test_case "No internal IPs in OpenAPI spec" \
    "! grep -E '192\.168\.|10\.|172\.(1[6-9]|2[0-9]|3[01])\.' openapi_v2_enhanced.json"

test_case "No hardcoded secrets" \
    "! grep -iE '(password|secret).*:.*\"[^\"]{10,}\"' openapi_v2_enhanced.json"

# ========== Summary ==========
echo ""
echo "=========================================="
echo "ğŸ“Š Acceptance Test Results"
echo "=========================================="
echo "âœ… Passed: $PASS"
echo "âŒ Failed: $FAIL"
echo "Total:     $((PASS + FAIL))"
echo "=========================================="

if [ $FAIL -eq 0 ]; then
    echo ""
    echo "ğŸ‰ All acceptance tests PASSED!"
    echo "âœ… Ready for production deployment"
    exit 0
else
    echo ""
    echo "âš ï¸  $FAIL tests FAILED!"
    echo "ğŸ”§ Review failures above and fix before deploying"
    exit 1
fi
```

**è¿è¡Œå®Œæ•´æµ‹è¯•**:

```bash
chmod +x scripts/acceptance_test_v2.sh
./scripts/acceptance_test_v2.sh
```

### 6.2 æ€§èƒ½å›å½’æµ‹è¯•

**å¯¹æ¯”è¿ç§»å‰åæ€§èƒ½**:

```bash
# 1. å¯¹æ¯”åŸºçº¿ (Day 1 çš„ç»“æœ)
echo "ğŸ“Š Comparing Performance: Before vs After Migration"
echo ""

# é‡æ–°è¿è¡ŒåŸºçº¿æµ‹è¯•
python scripts/baseline_performance.py

# 2. å¯¹æ¯”ç»“æœ
echo ""
echo "Comparing with baseline..."

python3 << 'PYTHON_SCRIPT'
import json

# åŠ è½½åŸºçº¿æ•°æ®
with open("baseline_performance.json") as f:
    baseline = json.load(f)

# åˆ†æ
print("\n" + "="*60)
print("Performance Comparison")
print("="*60)

for test in baseline:
    if "mean" in test:
        name = test["name"]
        mean = test["mean"] * 1000  # è½¬æ¢ä¸º ms
        p95 = test["p95"] * 1000

        # è®¡ç®—æ€§èƒ½ç›®æ ‡ (ä¸åº”è¶…è¿‡åŸºçº¿çš„ 105%)
        threshold = mean * 1.05

        status = "âœ… PASS" if mean <= threshold else "âŒ FAIL (regression)"

        print(f"{name:30s} {mean:6.0f}ms (P95: {p95:6.0f}ms) {status}")

print("="*60)
PYTHON_SCRIPT
```

### Day 6 éªŒæ”¶æ ‡å‡†

- [x] éªŒæ”¶æµ‹è¯• 20/20 å…¨éƒ¨é€šè¿‡
- [x] æ— æ€§èƒ½å›å½’ (æ‰€æœ‰ç«¯ç‚¹å»¶è¿Ÿ < åŸºçº¿ * 1.05)
- [x] SSE æµå¼æµ‹è¯•é€šè¿‡
- [x] å®‰å…¨æµ‹è¯•é€šè¿‡

---

## ğŸ”§ Day 7: æ–‡æ¡£å’Œæœ€ç»ˆéªŒæ”¶

### 7.1 æ›´æ–° README.md

**åœ¨ README.md ä¸­æ·»åŠ  Scalar è¯´æ˜**:

```markdown
## ğŸ“š API Documentation

We provide **three ways** to explore our API:

### 1. ğŸ¨ Scalar API Reference (Recommended) â­

Modern, interactive API documentation with beautiful UI.

- **URL**: http://localhost:8000/scalar
- **Features**:
  - ğŸ¯ Interactive "Try It Out" for all endpoints
  - ğŸ“ Code generation (Python, JavaScript, cURL, Go)
  - ğŸ” Powerful search across endpoints
  - ğŸ“± Mobile-friendly responsive design
  - ğŸ¨ Purple theme optimized for readability

**Quick Start**:
```bash
docker compose up -d api
open http://localhost:8000/scalar
```

### 2. ğŸ“– Swagger UI (Classic)

FastAPI's default interactive documentation.

- **URL**: http://localhost:8000/docs

### 3. ğŸ“˜ ReDoc

Three-panel API documentation.

- **URL**: http://localhost:8000/redoc

---

## ğŸš€ Quick API Test

1. **Health Check**:
   ```bash
   curl http://localhost:8000/api/v1/health
   ```

2. **Search Papers**:
   ```bash
   curl -X POST http://localhost:8000/api/v1/hybrid-search/ \
     -H "Content-Type: application/json" \
     -d '{"query": "transformer", "size": 5, "use_hybrid": true}'
   ```

3. **Ask Question (Agentic RAG)**:
   ```bash
   curl -X POST http://localhost:8000/api/v1/ask-agentic \
     -H "Content-Type: application/json" \
     -d '{"query": "What is attention mechanism?", "top_k": 3}'
   ```

---

## ğŸ“Š Service URLs

| Service | URL | Description |
|---------|-----|-------------|
| **Scalar Docs** â­ | http://localhost:8000/scalar | Modern API docs |
| **API** | http://localhost:8000 | FastAPI application |
| **Swagger UI** | http://localhost:8000/docs | Classic API docs |
| **ReDoc** | http://localhost:8000/redoc | Alternative docs |
| **Gradio** | http://localhost:7861 | Chat interface |
| **Langfuse** | http://localhost:3001 | Tracing dashboard |

---

## ğŸ› ï¸ For Developers

### Updating API Documentation

After modifying API endpoints, regenerate the OpenAPI spec:

```bash
# 1. Restart API
docker compose restart api

# 2. Validate OpenAPI spec
./scripts/validate_openapi.sh

# 3. Verify Scalar UI loads correctly
open http://localhost:8000/scalar
```
```

### 7.2 åˆ›å»ºç”¨æˆ·æŒ‡å—

**æ–‡ä»¶**: `docs/SCALAR_USER_GUIDE.md`

```markdown
# Scalar UI User Guide

## ğŸ¯ Overview

Scalar provides a modern, interactive interface for exploring the arXiv Paper Curator API.

## ğŸ“ Quick Navigation

### Access Scalar

```bash
# 1. Start the API
docker compose up -d api

# 2. Open Scalar in browser
open http://localhost:8000/scalar
```

### Interface Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Logo]  arXiv Paper Curator API            â”‚ â† Header
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Health  â”‚  GET /api/v1/health              â”‚
â”‚  Search  â”‚                                  â”‚
â”‚  RAG     â”‚  Returns service health status   â”‚ â† Content
â”‚  â”€â”€â”€â”€    â”‚                                  â”‚
â”‚          â”‚  [Try It Out] button             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†‘ Sidebar
```

## ğŸš€ Making Your First API Call

### Step 1: Navigate to Health Endpoint

1. In the left sidebar, click **"Health"**
2. Click **"GET /api/v1/health"**

### Step 2: Try It Out

1. Click the **"Try It Out"** button (top right)
2. Click **"Send Request"** (no parameters needed)
3. View the response below:

```json
{
  "status": "ok",
  "services": {
    "database": {"status": "healthy"},
    "opensearch": {"status": "healthy"},
    "ollama": {"status": "healthy"}
  },
  "version": "0.1.0"
}
```

## ğŸ’¬ Asking Questions (RAG)

### Basic RAG (/ask)

1. Navigate to **"ask"** â†’ **"POST /api/v1/ask"**
2. Click **"Try It Out"**
3. Modify the request body:

```json
{
  "query": "What are transformers in machine learning?",
  "top_k": 3,
  "use_hybrid": true,
  "model": "llama3.2:1b"
}
```

4. Click **"Send Request"**
5. Wait 3-5 seconds for the response

### Agentic RAG (/ask-agentic)

**For better quality answers with reasoning**:

1. Navigate to **"agentic-rag"** â†’ **"POST /api/v1/ask-agentic"**
2. Use the same request body as above
3. Response includes:
   - `answer`: The generated answer
   - `reasoning_steps`: How the system made decisions
   - `trace_id`: For debugging in Langfuse

## âš¡ Streaming Responses

### Important: Streaming Cannot Be Tested in Scalar UI

The `/stream` endpoint uses Server-Sent Events (SSE), which **cannot be tested interactively** in the browser UI.

### How to Test Streaming

**Use cURL**:

```bash
curl -N -X POST http://localhost:8000/api/v1/stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain attention mechanism",
    "top_k": 3
  }'
```

**Or use Python**:

```python
import httpx
import json

async with httpx.AsyncClient() as client:
    async with client.stream(
        "POST",
        "http://localhost:8000/api/v1/stream",
        json={"query": "What is attention?", "top_k": 3}
    ) as response:
        async for line in response.aiter_lines():
            if line.startswith("data: "):
                data = json.loads(line[6:])
                if "chunk" in data:
                    print(data["chunk"], end="", flush=True)
```

## ğŸ“ Code Generation

Scalar can generate client code in multiple languages.

### Generate Python Code

1. Make a successful API call (e.g., to `/health`)
2. Scroll to the **"Code Examples"** section
3. Select **"Python"** from the dropdown
4. Copy the generated code:

```python
import httpx

response = httpx.get("http://localhost:8000/api/v1/health")
print(response.json())
```

### Supported Languages

- Shell (cURL)
- Python (requests, httpx)
- JavaScript (fetch, axios)
- Go
- PHP

## ğŸ” Search Functionality

### Search for Endpoints

1. Press `/` or click the search box
2. Type: "search"
3. Results show all endpoints matching "search"

### Search in Descriptions

Type keywords like "streaming", "cache", "langfuse" to find related endpoints.

## ğŸ¨ Customization

### Change Theme

Scalar uses a **purple theme** by default. To change:

1. Open `static/api-docs.html`
2. Find the `theme:` line
3. Change to: `'blue'`, `'green'`, `'default'`, or `'moon'`
4. Refresh browser

### Change Server

Click the **server dropdown** (top of page) to switch between:
- Development (http://localhost:8000)
- Docker Internal (http://api:8000)

## ğŸ’¡ Tips & Tricks

### 1. Use Examples

Every endpoint has pre-filled examples. Click **"Use Example"** to autofill request bodies.

### 2. View Schemas

Scroll to the bottom of the sidebar to see **"Schemas"** section:
- `AskRequest`: Request format for RAG endpoints
- `AskResponse`: Response format
- `AgenticAskResponse`: Response with reasoning

### 3. Copy Responses

Click the **copy icon** in the response section to copy JSON to clipboard.

### 4. Keyboard Shortcuts

- `/` - Open search
- `Esc` - Close modals

## ğŸ› Troubleshooting

### "Network Error" when sending requests

**Cause**: API is not running

**Solution**:
```bash
docker compose up -d api
curl http://localhost:8000/api/v1/health  # Verify
```

### Scalar page is blank

**Cause**: OpenAPI spec not loading

**Solution**:
```bash
# Check spec is valid
curl http://localhost:8000/openapi.json | jq .

# Restart API
docker compose restart api

# Clear browser cache (Cmd+Shift+R)
```

### Request times out

**Cause**: LLM model not loaded or slow

**Solution**:
```bash
# Check Ollama service
docker compose exec ollama ollama list

# Use smaller model
{
  "model": "llama3.2:1b"  # Faster than llama3.2:3b
}
```

## ğŸ“ Support

- **GitHub Issues**: [Report bugs](https://github.com/Yemu-Yu/arxiv-paper-curator/issues)
- **Documentation**: [API_DOCUMENTATION.md](../API_DOCUMENTATION.md)
- **Blog**: [Implementation Guide](https://jamwithai.substack.com)
```

### 7.3 æœ€ç»ˆæ£€æŸ¥æ¸…å•

**æ–‡ä»¶**: `MIGRATION_CHECKLIST.md`

```markdown
# Scalar Migration Checklist

## âœ… Pre-Migration (Day 1)

- [ ] Performance baseline established (`baseline_performance.json` exists)
- [ ] All 4 baseline tests pass (health, spec, search, RAG)
- [ ] Original OpenAPI spec exported (`openapi_v1_original.json`)

## âœ… OpenAPI Enhancement (Day 2)

- [ ] `src/main.py` updated with enhanced metadata
- [ ] Custom `openapi()` function implemented
- [ ] Contact info and license added
- [ ] Server URLs configured
- [ ] Tags with descriptions defined
- [ ] `/stream` endpoint fixed (media_type = text/event-stream)
- [ ] OpenAPI validation passes (`openapi_v2_enhanced.json` created)
- [ ] Spectral linting has 0 errors

## âœ… Scalar UI (Day 3)

- [ ] `static/api-docs.html` created
- [ ] Static files mounted in FastAPI
- [ ] `/scalar` redirect works
- [ ] Scalar UI loads successfully
- [ ] All 6 endpoints visible in sidebar
- [ ] "Try it out" works for /health
- [ ] (Optional) Nginx container configured

## âœ… SSE Testing (Day 4)

- [ ] `tests/test_sse_streaming.py` created
- [ ] All SSE tests pass (basic flow, cache, errors)
- [ ] Streaming performance better than non-streaming TTFB
- [ ] Event sequence correct (metadata â†’ chunks â†’ done)

## âœ… Security (Day 5)

- [ ] Security audit script run
- [ ] Risk score â‰¤ 20 (Grade B+)
- [ ] No internal IPs exposed
- [ ] No hardcoded secrets
- [ ] Example data sanitized
- [ ] Contact email updated (not example.com)

## âœ… Testing (Day 6)

- [ ] Acceptance tests 20/20 pass
- [ ] No performance regression (< 5% slower)
- [ ] SSE integration tests pass
- [ ] Security tests pass

## âœ… Documentation (Day 7)

- [ ] README.md updated with Scalar section
- [ ] `docs/SCALAR_USER_GUIDE.md` created
- [ ] All service URLs documented
- [ ] Developer guide for updating docs added

## âœ… Final Validation

- [ ] All Docker services running: `docker compose ps`
- [ ] Scalar UI accessible: http://localhost:8000/scalar
- [ ] All endpoints testable in Scalar
- [ ] Code examples generate correctly
- [ ] Search functionality works

## ğŸ“Š Metrics to Track

| Metric | Target | Actual |
|--------|--------|--------|
| OpenAPI endpoints | 6 | ___ |
| Acceptance tests pass | 20/20 | ___ |
| Risk score | â‰¤ 20 | ___ |
| Health check latency | < 100ms | ___ ms |
| OpenAPI spec latency | < 500ms | ___ ms |
| SSE TTFB improvement | > 30% | ___% |

## ğŸ¯ Sign-Off

- [ ] Technical Lead approval
- [ ] QA validation complete
- [ ] Documentation reviewed
- [ ] Ready for production

**Signed**: ________________
**Date**: ________________
```

### Day 7 éªŒæ”¶æ ‡å‡†

- [x] `MIGRATION_CHECKLIST.md` æ‰€æœ‰é¡¹ç›®å‹¾é€‰å®Œæˆ
- [x] README.md æ›´æ–°
- [x] `docs/SCALAR_USER_GUIDE.md` åˆ›å»º
- [x] æ‰€æœ‰æ–‡æ¡£é“¾æ¥æœ‰æ•ˆ
- [x] å›¢é˜Ÿæˆå‘˜å¯ä»¥ä½¿ç”¨ Scalar UI è¿›è¡Œ API æµ‹è¯•

---

## âœ… æœ€ç»ˆéªŒæ”¶æ ‡å‡† (å®Œæ•´ç‰ˆ)

### æŠ€æœ¯éªŒæ”¶

| ç±»åˆ« | æ£€æŸ¥é¡¹ | çŠ¶æ€ |
|------|--------|------|
| **API åŠŸèƒ½** | æ‰€æœ‰ 6 ä¸ªç«¯ç‚¹æ­£å¸¸å·¥ä½œ | [ ] |
| | æ€§èƒ½æ— å›å½’ (< 5% æ…¢) | [ ] |
| | SSE æµå¼æ­£å¸¸ | [ ] |
| **OpenAPI** | è§„èŒƒç¬¦åˆ 3.x æ ‡å‡† | [ ] |
| | æ‰€æœ‰ç«¯ç‚¹æœ‰ examples | [ ] |
| | æ‰€æœ‰ç«¯ç‚¹æœ‰ operation_id | [ ] |
| | é”™è¯¯å“åº”å®Œæ•´å®šä¹‰ | [ ] |
| **Scalar UI** | UI å¯è®¿é—® (http://localhost:8000/scalar) | [ ] |
| | åŠ è½½ OpenAPI spec æˆåŠŸ | [ ] |
| | æ‰€æœ‰ç«¯ç‚¹å¯è§ | [ ] |
| | "Try it out" åŠŸèƒ½æ­£å¸¸ | [ ] |
| | ä»£ç ç”Ÿæˆå™¨å·¥ä½œ | [ ] |
| | æœç´¢åŠŸèƒ½æ­£å¸¸ | [ ] |
| **å®‰å…¨** | é£é™©åˆ†æ•° â‰¤ 20 | [ ] |
| | æ— æ•æ„Ÿä¿¡æ¯æ³„éœ² | [ ] |
| | è”ç³»ä¿¡æ¯æœ‰æ•ˆ | [ ] |
| **æµ‹è¯•** | éªŒæ”¶æµ‹è¯• 20/20 é€šè¿‡ | [ ] |
| | SSE é›†æˆæµ‹è¯•é€šè¿‡ | [ ] |
| | æ€§èƒ½åŸºçº¿å»ºç«‹ | [ ] |
| **æ–‡æ¡£** | README.md æ›´æ–° | [ ] |
| | ç”¨æˆ·æŒ‡å—å®Œæ•´ | [ ] |
| | è¿ç§»æ£€æŸ¥æ¸…å•å®Œæˆ | [ ] |

### ç”¨æˆ·éªŒæ”¶

- [ ] æ–°ç”¨æˆ·å¯åœ¨ 5 åˆ†é’Ÿå†…å®Œæˆé¦–æ¬¡ API è°ƒç”¨
- [ ] Scalar UI åœ¨ç§»åŠ¨ç«¯å¯æ­£å¸¸æµè§ˆ
- [ ] ä»£ç ç¤ºä¾‹å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
- [ ] é”™è¯¯ä¿¡æ¯æ¸…æ™°æ˜“æ‡‚

### æ€§èƒ½éªŒæ”¶

| ç«¯ç‚¹ | åŸºçº¿ P95 | è¿ç§»å P95 | å˜åŒ– | çŠ¶æ€ |
|------|---------|-----------|------|------|
| /health | â‰¤ 100ms | ___ ms | ___% | [ ] |
| /openapi.json | â‰¤ 500ms | ___ ms | ___% | [ ] |
| /hybrid-search | â‰¤ 600ms | ___ ms | ___% | [ ] |
| /ask | â‰¤ 4000ms | ___ ms | ___% | [ ] |
| /stream (TTFB) | â‰¤ 600ms | ___ ms | ___% | [ ] |

### å®‰å…¨éªŒæ”¶

- [ ] OpenAPI spec ä¸åŒ…å«å†…éƒ¨ IP åœ°å€
- [ ] æ— ç¡¬ç¼–ç å¯†é’¥æˆ– token
- [ ] æ— ç¯å¢ƒå˜é‡æ³„éœ²
- [ ] ç¤ºä¾‹æ•°æ®å·²è„±æ•
- [ ] è”ç³»é‚®ç®±éå ä½ç¬¦

---

## ğŸ†š V1 vs V2 å¯¹æ¯”

### ä¸»è¦æ”¹è¿›

| æ–¹é¢ | V1 è®¡åˆ’ | V2 è®¡åˆ’ (ä¿®è®¢ç‰ˆ) | æ”¹è¿› |
|------|---------|----------------|------|
| **éƒ¨ç½²æ–¹å¼** | Docker å®¹å™¨ (ä¸å­˜åœ¨çš„é•œåƒ) | é™æ€ HTML (CDN) | âœ… å¯æ‰§è¡Œ |
| **SSE æ–‡æ¡£** | ä¸å¯è¡Œçš„ schema | é™çº§ç­–ç•¥ + ä»£ç ç¤ºä¾‹ | âœ… å®ç”¨ |
| **æ—¶é—´** | 10 å¤© | 7 å¤© | âœ… æ›´å¿« |
| **éªŒæ”¶** | æŠ½è±¡æ ‡å‡† | å¯æ‰§è¡Œæµ‹è¯•è„šæœ¬ | âœ… å¯éªŒè¯ |
| **å®‰å…¨** | æœªè¯„ä¼° | å®Œæ•´å®¡è®¡æµç¨‹ | âœ… æ›´å®‰å…¨ |
| **æ€§èƒ½** | æ— åŸºçº¿ | å»ºç«‹åŸºçº¿ + å›å½’æµ‹è¯• | âœ… å¯ç›‘æ§ |

### ç§»é™¤çš„å†…å®¹

- âŒ Scalar Gateway (ä¸éœ€è¦)
- âŒ API ç‰ˆæœ¬ç®¡ç† (éå¿…éœ€)
- âŒ Mock Server (éæ ¸å¿ƒ)
- âŒ API è®¤è¯å®ç° (æœªæ¥åŠŸèƒ½)

### æ–°å¢å†…å®¹

- âœ… æ€§èƒ½åŸºçº¿æµ‹è¯•
- âœ… å®‰å…¨å®¡è®¡è„šæœ¬
- âœ… SSE é›†æˆæµ‹è¯•
- âœ… å®Œæ•´éªŒæ”¶è„šæœ¬
- âœ… ç”¨æˆ·æŒ‡å—

---

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

### é‡åˆ°é—®é¢˜?

1. **æ£€æŸ¥æ—¥å¿—**:
   ```bash
   docker compose logs api -f
   ```

2. **éªŒè¯ OpenAPI**:
   ```bash
   ./scripts/validate_openapi.sh
   ```

3. **è¿è¡Œè¯Šæ–­**:
   ```bash
   ./scripts/acceptance_test_v2.sh
   ```

### æŠ¥å‘Šé—®é¢˜

- **GitHub Issues**: https://github.com/Yemu-Yu/arxiv-paper-curator/issues
- **æ ‡ç­¾**: `scalar-migration`, `documentation`, `api`

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [Scalar Documentation](https://docs.scalar.com)
- [FastAPI OpenAPI](https://fastapi.tiangolo.com/advanced/extending-openapi/)
- [OpenAPI 3.1 Specification](https://spec.openapis.org/oas/v3.1.0)

### å†…éƒ¨æ–‡æ¡£

- [API_DOCUMENTATION.md](API_DOCUMENTATION.md) - å®Œæ•´ API è§„èŒƒ
- [CLAUDE.md](CLAUDE.md) - é¡¹ç›®æ¶æ„æŒ‡å—
- [SCALAR_MIGRATION_PLAN.md](SCALAR_MIGRATION_PLAN.md) - åŸå§‹è¿ç§»è®¡åˆ’

---

**æœ€åæ›´æ–°**: 2025-12-07
**ç‰ˆæœ¬**: 2.0 (ä¿®è®¢ç‰ˆ)
**çŠ¶æ€**: âœ… Ready for Implementation
